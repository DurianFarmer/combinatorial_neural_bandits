{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4Q1y1fVZBNJ"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1612114370931,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "BxJjrGbzZBNM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "import abc\n",
    "\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "if not os.path.exists('regrets'):\n",
    "    os.mkdir('regrets')\n",
    "\n",
    "SEED_HIDDEN = 1000\n",
    "SEED_FEATURE = 2000\n",
    "SEED_NOISE = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izb_VuXOZBNT"
   },
   "source": [
    "# Experiment descirption\n",
    "### Hidden functions\n",
    "- Linear: $h_{1}(\\mathbf{x}_{t,i}) = \\mathbf{x}_{t,i}^{\\top}\\mathbf{a}$\n",
    "- Quadratic: $h_{2}(\\mathbf{x}_{t,i}) = (\\mathbf{x}_{t,i}^{\\top}\\mathbf{a})^{2}$\n",
    "- Non-linear: $h_{3}(\\mathbf{x}_{t,i}) = \\cos(\\pi \\mathbf{x}_{t,i}^{\\top}\\mathbf{a})$\n",
    "- where $\\mathbf{a} \\sim N(0,1)$ and then normalized\n",
    "\n",
    "### For each hidden function, compare the following algorithms\n",
    "- CombLinUCB\n",
    "- CombLinTS\n",
    "- CN-UCB\n",
    "- CN-TS(1): single reward sample\n",
    "- CN-TS(30): optimistic sampling, sample size = 30 (default sample size is 1)\n",
    "\n",
    "### Ablation study of feature dimension *d* and neural network width *m*\n",
    "- Default value: $d = 20, m = 20$\n",
    "- $d = \\{20, 40\\}$  for all algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giwELIVSZBNT"
   },
   "source": [
    "# Experiment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1612114697379,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "qBJKM4RXZBNa"
   },
   "outputs": [],
   "source": [
    "def inv_sherman_morrison_iter(a, A_inv):\n",
    "    \"\"\"Inverse of a matrix for combinatorial case.\n",
    "    \"\"\"\n",
    "    temp = A_inv    \n",
    "    for u in a:                     \n",
    "        Au = torch.matmul(temp, u)\n",
    "        temp = temp - torch.ger(Au, Au)/(1+torch.matmul(u.T, Au))    \n",
    "    return temp       \n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Template for fully connected neural network for scalar approximation.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_size=1, \n",
    "                 hidden_size=2,\n",
    "                 n_layers=1,\n",
    "                 activation='ReLU',\n",
    "                 p=0.0,\n",
    "                ):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        if self.n_layers == 1:\n",
    "            self.layers = [nn.Linear(input_size, 1)]                        \n",
    "        else:\n",
    "            size  = [input_size] + [hidden_size,] * (self.n_layers-1) + [1]\n",
    "            ##\n",
    "            self.layers = [nn.Linear(size[i], size[i+1], bias=False) \\\n",
    "                           for i in range(self.n_layers)]\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "        \n",
    "        # activation function\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == 'ReLU':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'LeakyReLU':\n",
    "            self.activation = nn.LeakyReLU(negative_slope=0.1)\n",
    "        else:\n",
    "            raise Exception('{} not an available activation'.format(activation))\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_layers-1):\n",
    "            x = self.dropout(self.activation(self.layers[i](x)))\n",
    "        x = self.layers[-1](x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit():\n",
    "    def __init__(self,\n",
    "                 T,\n",
    "                 n_arms,                 \n",
    "                 n_features,                                  \n",
    "                 h,                                                   \n",
    "                 noise_std=1.0,                 \n",
    "                 n_assortment=1,\n",
    "                 n_samples=1,\n",
    "                 round_reward_function=sum,\n",
    "                 device=torch.device('cpu'),\n",
    "                 n_sim=20,\n",
    "                 unif=False\n",
    "                ):\n",
    "        # number of rounds\n",
    "        self.T = T\n",
    "        # number of arms\n",
    "        self.n_arms = n_arms\n",
    "        # number of features for each arm\n",
    "        self.n_features = n_features        \n",
    "        \n",
    "        # average reward function\n",
    "        # h : R^d -> R\n",
    "        self.h = h\n",
    "\n",
    "        # standard deviation of Gaussian reward noise\n",
    "        self.noise_std = noise_std\n",
    "        \n",
    "        # number of assortment (top-K)\n",
    "        self.n_assortment = n_assortment                \n",
    "        \n",
    "        # (TS) number of samples for each round and arm\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "        # round reward function\n",
    "        self.round_reward_function = round_reward_function                \n",
    "        \n",
    "        # device\n",
    "        self.device = device\n",
    "        \n",
    "        # number of simulation\n",
    "        self.n_sim = n_sim\n",
    "        \n",
    "        # generate feature vectors and noise\n",
    "        self.X = self.generate_features(unif)\n",
    "        self.xi = self.generate_noise()\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def arms(self):\n",
    "        \"\"\"Return [0, ...,n_arms-1]\n",
    "        \"\"\"\n",
    "        return range(self.n_arms)\n",
    "    \n",
    "    def generate_features(self, unif):\n",
    "        \"\"\"Generate feature vectors for every round and simulation\n",
    "        \"\"\"\n",
    "        X = np.zeros((self.n_sim, self.T, self.n_arms, self.n_features))\n",
    "        \n",
    "        # set random seed for feature vector\n",
    "        np.random.seed(SEED_FEATURE)\n",
    "        for i in range(self.n_sim):\n",
    "            if unif:\n",
    "                x = np.random.uniform(low=-1.0, high=1.0, size=(self.T, self.n_arms, self.n_features))\n",
    "            else:\n",
    "                x = np.random.randn(self.T, self.n_arms, self.n_features)\n",
    "            x /= np.repeat(np.linalg.norm(x, axis=-1, ord=2), self.n_features).reshape(self.T, self.n_arms, self.n_features)\n",
    "            X[i] = x\n",
    "        return torch.from_numpy(X).to(self.device) \n",
    "    \n",
    "    def generate_noise(self):\n",
    "        \"\"\"Generate noise for every round and simulation\n",
    "        \"\"\"\n",
    "        xi = np.zeros((self.n_sim, self.T, self.n_arms))\n",
    "        \n",
    "        # set random seed for noise\n",
    "        np.random.seed(SEED_NOISE)\n",
    "        for i in range(self.n_sim):   \n",
    "            x = np.random.randn(self.T, self.n_arms)        \n",
    "            xi[i] = x\n",
    "        return torch.from_numpy(xi).to(device)\n",
    "                                                                            \n",
    "    def reset(self, i):\n",
    "        \"\"\"Generate new features and new rewards.\n",
    "        \"\"\"\n",
    "        self.reset_features(i)\n",
    "        self.reset_rewards(i)\n",
    "    \n",
    "    def reset_features(self, i):\n",
    "        \"\"\"Generate normalized random N(0,1) features.\n",
    "        \"\"\"        \n",
    "        self.features = self.X[i]    \n",
    "\n",
    "    def reset_rewards(self, i):\n",
    "        \"\"\"Generate rewards for each arm and each round,\n",
    "        following the reward function h + Gaussian noise.\n",
    "        \"\"\"            \n",
    "        self.rewards = torch.Tensor(\n",
    "            [\n",
    "                self.h( self.features[t, k] ) + self.noise_std*self.xi[i][t][k] \n",
    "                for t,k in itertools.product(range(self.T), range(self.n_arms))\n",
    "            ]\n",
    "        ).reshape(self.T, self.n_arms)\n",
    "\n",
    "        ## to be used only to compute regret, NOT by the algorithm itself        \n",
    "        a = self.rewards.to('cpu').numpy()\n",
    "        ind = np.argpartition(a, -1*self.n_assortment, axis=1)[:,-1*self.n_assortment:]        \n",
    "        s_ind = np.array([list(ind[i][np.argsort(a[i][ind[i]])][::-1]) for i in range(0, np.shape(a)[0])])\n",
    "        \n",
    "        self.best_super_arm = torch.from_numpy(s_ind).to(self.device)\n",
    "        self.best_rewards = torch.Tensor([a[i][s_ind[i]] for i in range(0,np.shape(a)[0])]).to(self.device)\n",
    "        self.best_round_reward = self.round_reward_function(self.best_rewards).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1612114698036,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "BDp-SK0YZBNb"
   },
   "outputs": [],
   "source": [
    "class UCB_TS(abc.ABC):\n",
    "    \"\"\"Base class for UCB and TS methods.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ucb_ts, ## A string. \"UCB\" for UCB, \"TS\" for TS\n",
    "                 bandit,\n",
    "                 reg_factor=1.0,\n",
    "                 confidence_scaling_factor=1, ## for UCB, gamma\n",
    "                 exploration_variance=1, ## for TS, nu\n",
    "                 delta=0.1,\n",
    "                 training_period=1,\n",
    "                 throttle=int(1e2),\n",
    "                 device=torch.device('cpu')\n",
    "                ):\n",
    "        ## select whether UCB or TS\n",
    "        self.ucb_ts = ucb_ts\n",
    "        # bandit object, contains features and generated rewards\n",
    "        self.bandit = bandit\n",
    "        # L2 regularization strength\n",
    "        self.reg_factor = reg_factor\n",
    "        # Confidence bound with probability 1-delta\n",
    "        self.delta = delta\n",
    "\n",
    "        # multiplier for the confidence bound            \n",
    "        self.confidence_scaling_factor = confidence_scaling_factor\n",
    "\n",
    "        # exploration variance for TS\n",
    "        self.exploration_variance = exploration_variance\n",
    "        \n",
    "        # train approximator only few rounds\n",
    "        self.training_period = training_period\n",
    "        \n",
    "        # throttle tqdm updates\n",
    "        self.throttle = throttle\n",
    "        \n",
    "        # device\n",
    "        self.device = device\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    ## for UCB\n",
    "    def reset_upper_confidence_bounds(self):\n",
    "        \"\"\"Initialize upper confidence bounds and related quantities.\n",
    "        \"\"\"\n",
    "        if self.ucb_ts == \"UCB\":\n",
    "            self.exploration_bonus = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.mu_hat = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.upper_confidence_bounds = torch.ones((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    ## for TS\n",
    "    def reset_sample_rewards(self):\n",
    "        \"\"\"Initialize sample rewards and related quantities.\n",
    "        \"\"\"\n",
    "        if self.ucb_ts == \"TS\":\n",
    "            self.sigma_square = torch.ones((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.mu_hat = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.sample_rewards = torch.zeros((self.bandit.T, self.bandit.n_arms, self.bandit.n_samples)).to(self.device)\n",
    "            self.optimistic_sample_rewards = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def reset_regrets(self):\n",
    "        \"\"\"Initialize regrets.\n",
    "        \"\"\"\n",
    "        self.regrets = torch.zeros(self.bandit.T).to(self.device)\n",
    "\n",
    "    def reset_actions(self):\n",
    "        \"\"\"Initialize cache of actions (actions: played set of arms of each round).\n",
    "        \"\"\"\n",
    "        self.actions = torch.zeros((self.bandit.T, self.bandit.n_assortment)).to(self.device)\n",
    "    \n",
    "    def reset_A_inv(self):\n",
    "        \"\"\"Initialize n_arms square matrices representing the inverses\n",
    "        of exploration bonus matrices.\n",
    "        \"\"\"\n",
    "        self.A_inv = torch.eye(self.approximator_dim).to(self.device)/self.reg_factor        \n",
    "    \n",
    "    def reset_grad_approx(self):\n",
    "        \"\"\"Initialize the gradient of the approximator w.r.t its parameters.\n",
    "        \"\"\"\n",
    "        self.grad_approx = torch.zeros((self.bandit.n_arms, self.approximator_dim)).to(self.device)\n",
    "        \n",
    "    def sample_action(self):        \n",
    "        \"\"\"Return the action (set of arms) to play based on current estimates\n",
    "        \"\"\"\n",
    "        ## for UCB\n",
    "        if self.ucb_ts == \"UCB\":\n",
    "            a = self.upper_confidence_bounds[self.iteration].to('cpu').numpy()\n",
    "        ## for TS\n",
    "        if self.ucb_ts == \"TS\":\n",
    "            a = self.optimistic_sample_rewards[self.iteration].to('cpu').numpy()\n",
    "\n",
    "        ind = np.argpartition(a, -1*self.bandit.n_assortment)[-1*self.bandit.n_assortment:]\n",
    "        s_ind = ind[np.argsort(a[ind])][::-1]\n",
    "        return torch.Tensor(s_ind.copy()).to(self.device)               \n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def reset(self):\n",
    "        \"\"\"Initialize variables of interest.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def approximator_dim(self):\n",
    "        \"\"\"Number of parameters used in the approximator.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def confidence_multiplier(self):\n",
    "        \"\"\"Multiplier for the confidence exploration bonus.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def update_confidence_bounds(self):\n",
    "        \"\"\"Update the confidence bounds for all arms at time t.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update_output_gradient(self):\n",
    "        \"\"\"Compute output gradient of the approximator w.r.t its parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def train(self):\n",
    "        \"\"\"Update approximator.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def predict(self):\n",
    "        \"\"\"Predict rewards based on an approximator.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    ## for UCB\n",
    "    def update_confidence_bounds(self):\n",
    "        \"\"\"Update confidence bounds and related quantities for all set of arms.\n",
    "        \"\"\"\n",
    "        # update self.grad_approx\n",
    "        self.update_output_gradient()\n",
    "        \n",
    "        # UCB exploration bonus\n",
    "        self.exploration_bonus[self.iteration] = torch.Tensor(\n",
    "            [\n",
    "                self.confidence_multiplier * torch.sqrt(torch.dot(self.grad_approx[a], torch.matmul(self.A_inv, self.grad_approx[a].T))) for a in self.bandit.arms\n",
    "            ]\n",
    "        )        \n",
    "        \n",
    "        # update reward prediction mu_hat\n",
    "        self.predict()\n",
    "        \n",
    "        # estimated combined bound for reward\n",
    "        self.upper_confidence_bounds[self.iteration] = self.mu_hat[self.iteration] + self.exploration_bonus[self.iteration]\n",
    "\n",
    "    ## for TS\n",
    "    def update_sample_rewards(self):\n",
    "        \"\"\"Update sample rewards and related quantities for all set of arms.\n",
    "        \"\"\"        \n",
    "        # update self.grad_approx\n",
    "        self.update_output_gradient() \n",
    "        \n",
    "        # update sigma_square        \n",
    "        self.sigma_square[self.iteration] = torch.Tensor([self.reg_factor * \\\n",
    "                                             torch.dot(self.grad_approx[a], torch.matmul(self.A_inv, self.grad_approx[a].T)) \\\n",
    "                                             for a in self.bandit.arms]).to(self.device)\n",
    "                \n",
    "        # update reward prediction mu_hat\n",
    "        self.predict()\n",
    "        \n",
    "        # update sample reward\n",
    "        self.sample_multi_rewards()\n",
    "        \n",
    "        # update optimistic sample reward for each arm\n",
    "        for a in self.bandit.arms:\n",
    "            self.optimistic_sample_rewards[self.iteration][a] = torch.max(self.sample_rewards[self.iteration][a])\n",
    "    \n",
    "    def sample_multi_rewards():\n",
    "        self.sample_rewards.to('cpu')\n",
    "        for a in self.bandit.arms:\n",
    "            for j in range(self.bandit.n_samples):\n",
    "                self.sample_rewards[self.iteration][a][j] = np.random.normal(loc = self.mu_hat[self.iteration, a].to('cpu'),\n",
    "                                                                             scale = (self.exploration_variance**2) * self.sigma_square[self.iteration, a].to('cpu')\n",
    "                                                                            )                                                                                                                                           \n",
    "        self.sample_rewards.to(self.device)\n",
    "    \n",
    "    def update_A_inv(self):\n",
    "        \"\"\"Update A_inv by using an iteration of Sherman_Morrison formula\n",
    "        \"\"\"\n",
    "        self.A_inv = inv_sherman_morrison_iter(\n",
    "            self.grad_approx[self.action.to('cpu').numpy()],\n",
    "            self.A_inv\n",
    "        )               \n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"Run an episode of bandit.\n",
    "        \"\"\"\n",
    "        postfix = {\n",
    "            'total regret': 0.0,\n",
    "            '% optimal set of arms': 0.0,\n",
    "        }\n",
    "        with tqdm(total=self.bandit.T, postfix=postfix) as pbar:\n",
    "            for t in range(self.bandit.T):                \n",
    "                ## for UCB\n",
    "                if self.ucb_ts == \"UCB\":\n",
    "                    # update confidence of all set of arms based on observed features at time t\n",
    "                    self.update_confidence_bounds()\n",
    "                ## for TS\n",
    "                if self.ucb_ts == \"TS\":\n",
    "                    ## update sample rewards of all set of arms based on observed features at time t\n",
    "                    self.update_sample_rewards()                \n",
    "                \n",
    "                # pick action (set of arm) with the highest boosted estimated reward\n",
    "                self.action = self.sample_action()\n",
    "                self.actions[t] = self.action\n",
    "                # update approximator                          \n",
    "                self.train() ### lin and neural training are different\n",
    "                # update exploration indicator A_inv\n",
    "                self.update_A_inv()\n",
    "                \n",
    "                ## compute regret                \n",
    "                self.regrets[t] = self.bandit.best_round_reward[t] - self.bandit.round_reward_function(self.bandit.rewards[t, self.action.to('cpu').numpy()])                 \n",
    "                \n",
    "                # increment counter\n",
    "                self.iteration += 1\n",
    "                \n",
    "                # log\n",
    "                postfix['total regret'] += self.regrets[t].to('cpu').numpy()\n",
    "                n_optimal_arm = np.sum(\n",
    "                    np.prod(\n",
    "                        (self.actions[:self.iteration].to('cpu').numpy()==self.bandit.best_super_arm[:self.iteration].to('cpu').numpy())*1, \n",
    "                        axis=1)                                                          \n",
    "                )\n",
    "                postfix['% optimal set of arms'] = '{:.2%}'.format(n_optimal_arm / self.iteration)\n",
    "                \n",
    "                if t % self.throttle == 0:\n",
    "                    pbar.set_postfix(postfix)\n",
    "                    pbar.update(self.throttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1612114698036,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "4tvBEQ33ZBNg"
   },
   "outputs": [],
   "source": [
    "class Neural(UCB_TS):\n",
    "    \"\"\"CN-UCB or CN-TS.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ucb_ts, ## A string. \"UCB\" for UCB, \"TS\" for TS\n",
    "                 bandit,\n",
    "                 hidden_size=20,\n",
    "                 n_layers=2,\n",
    "                 reg_factor=1.0,\n",
    "                 delta=0.01,\n",
    "                 confidence_scaling_factor=1, ## for UCB\n",
    "                 exploration_variance=1, ## for TS\n",
    "                 training_window=100,\n",
    "                 p=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 epochs=1,\n",
    "                 training_period=1,\n",
    "                 throttle=1,\n",
    "                 device=torch.device('cpu'),\n",
    "                ):\n",
    "\n",
    "        # hidden size of the NN layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # number of layers\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # number of rewards in the training buffer\n",
    "        self.training_window = training_window\n",
    "        \n",
    "        # NN parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.device = device\n",
    "            \n",
    "        # dropout rate\n",
    "        self.p = p\n",
    "\n",
    "        # neural network\n",
    "        self.model = Model(input_size=bandit.n_features, \n",
    "                           hidden_size=self.hidden_size,\n",
    "                           n_layers=self.n_layers,\n",
    "                           p=self.p\n",
    "                          ).to(self.device)        \n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        super().__init__(ucb_ts,\n",
    "                         bandit, \n",
    "                         reg_factor=reg_factor,\n",
    "                         confidence_scaling_factor=confidence_scaling_factor, ## for UCB\n",
    "                         exploration_variance=exploration_variance, ## for TS\n",
    "                         delta=delta,\n",
    "                         throttle=throttle,\n",
    "                         training_period=training_period,\n",
    "                         device=self.device\n",
    "                        )\n",
    "\n",
    "    @property\n",
    "    def approximator_dim(self):\n",
    "        \"\"\"Sum of the dimensions of all trainable layers in the network.\n",
    "        \"\"\"\n",
    "        return sum(w.numel() for w in self.model.parameters() if w.requires_grad)\n",
    "    \n",
    "    @property\n",
    "    def confidence_multiplier(self):\n",
    "        \"\"\"Constant equal to confidence_scaling_factor\n",
    "        \"\"\"\n",
    "        return self.confidence_scaling_factor\n",
    "    \n",
    "    def update_output_gradient(self):\n",
    "        \"\"\"Get gradient of network prediction w.r.t network weights.\n",
    "        \"\"\"\n",
    "        for a in self.bandit.arms:\n",
    "            \n",
    "            x = self.bandit.features[self.iteration, a].reshape(1,-1).float()                \n",
    "            \n",
    "            self.model.zero_grad()\n",
    "            y = self.model(x)\n",
    "            y.backward()\n",
    "                        \n",
    "            self.grad_approx[a] = torch.cat([\n",
    "                w.grad.detach().flatten() / np.sqrt(self.hidden_size)\n",
    "                for w in self.model.parameters() if w.requires_grad]\n",
    "            ).to(self.device)\n",
    "            \n",
    "            \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal estimates.\n",
    "        \"\"\"\n",
    "        self.reset_upper_confidence_bounds() ## for UCB\n",
    "        self.reset_sample_rewards() ## for TS\n",
    "        self.reset_regrets()\n",
    "        self.reset_actions()\n",
    "        self.reset_A_inv()\n",
    "        self.reset_grad_approx()\n",
    "        self.iteration = 0\n",
    "\n",
    "    ## inital parameters\n",
    "    def set_init_param(self, parameters):\n",
    "        self.init_param = self.param_to_tensor(parameters)\n",
    "\n",
    "    ## torch Parameter object to Tensor object\n",
    "    def param_to_tensor(self, parameters):\n",
    "        a = torch.empty(1).to(self.device)\n",
    "        for p in parameters:\n",
    "            a = torch.cat((a, p.data.flatten()))\n",
    "        return a[1:].to(self.device)    \n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Train neural approximator.        \n",
    "        \"\"\"\n",
    "        ### train only when training_period occurs\n",
    "        if self.iteration % self.training_period == 0:                        \n",
    "            iterations_so_far = range(np.max([0, self.iteration-self.training_window]), self.iteration+1)\n",
    "            actions_so_far = self.actions[np.max([0, self.iteration-self.training_window]):self.iteration+1].to('cpu').numpy() # this is a matrix            \n",
    "\n",
    "            temp = torch.cat([self.bandit.features[t, actions_so_far[i]] for i, t in enumerate(iterations_so_far)])\n",
    "            x_train = torch.reshape(temp, (1,-1,self.bandit.n_features)).squeeze().float().to(self.device)\n",
    "\n",
    "            temp = torch.cat([self.bandit.rewards[t, actions_so_far[i]] for i, t in enumerate(iterations_so_far)])\n",
    "            y_train = torch.reshape(temp, (1,-1)).squeeze().float().to(self.device)\n",
    "\n",
    "            # train mode\n",
    "            self.model.train()\n",
    "            for _ in range(self.epochs):\n",
    "                ## computing the regularization parameter\n",
    "                tmp = (self.param_to_tensor(self.model.parameters()) - self.init_param).to(torch.device('cpu')).numpy()\n",
    "                param_diff = np.linalg.norm(tmp)\n",
    "                regularization = (self.reg_factor*self.hidden_size*param_diff**2)/2\n",
    "\n",
    "                ## update weight\n",
    "                y_pred = self.model.forward(x_train).squeeze()\n",
    "                ### loss = nn.MSELoss()(y_train, y_pred)\n",
    "                loss = nn.MSELoss(reduction='sum')(y_train, y_pred)/2 + regularization            \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        else:\n",
    "            pass\n",
    "                                        \n",
    "    def predict(self):\n",
    "        \"\"\"Predict reward.\n",
    "        \"\"\"\n",
    "        # eval mode\n",
    "        self.model.eval()        \n",
    "        self.mu_hat[self.iteration] = self.model.forward(self.bandit.features[self.iteration].float()).detach().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajS2SB-QZBNU"
   },
   "source": [
    "### Hidden function, bandit, learning algorithm and regret settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI = 3.14\n",
    "\n",
    "h1 = \"h1\"\n",
    "h2 = \"h2\"\n",
    "h3 = \"h3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(lin_neural, ucb_ts, h_str, n_features=20, hidden_size=100, n_samples=1, save = '', n_sim=20, unif=False):\n",
    "    \"\"\" kind explanation\n",
    "    \"\"\"\n",
    "    ## set random seed for hidden function\n",
    "    np.random.seed(SEED_HIDDEN)    \n",
    "    \n",
    "    ## Hidden function\n",
    "    tmp = np.random.randn(n_features)\n",
    "    a = torch.from_numpy(tmp / np.linalg.norm(tmp, ord=2)).to(device)\n",
    "    \n",
    "    if h_str == \"h1\":\n",
    "        T = 1000\n",
    "        def h(x):\n",
    "            return torch.dot(x, a).to(device)    \n",
    "    elif h_str == \"h2\":\n",
    "        T = 1000\n",
    "        def h(x):\n",
    "            return (torch.dot(x, a)**2).to(device)    \n",
    "    elif h_str == \"h3\":\n",
    "        T = 2000\n",
    "        def h(x):\n",
    "            return torch.cos(PI*torch.dot(x, a)).to(device)\n",
    "    \n",
    "    ## Bandit\n",
    "    bandit = Bandit(T,\n",
    "                    n_arms,\n",
    "                    n_features, \n",
    "                    h,\n",
    "                    noise_std=noise_std,\n",
    "                    n_assortment=n_assortment,\n",
    "                    n_samples=n_samples,\n",
    "                    round_reward_function=F,\n",
    "                    device=device,\n",
    "                    n_sim=n_sim,\n",
    "                    unif=unif\n",
    "                   )\n",
    "       \n",
    "    ## Learning algorithm and regret\n",
    "    regrets = np.empty((n_sim, T))\n",
    "    \n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        bandit.reset(i) # use the pre-generated feature vectors and noises for i-th simulation\n",
    "        \n",
    "        if lin_neural == Neural:\n",
    "            model = Neural(ucb_ts,\n",
    "                           bandit,\n",
    "                           hidden_size,\n",
    "                           reg_factor=reg_factor,\n",
    "                           delta=delta,\n",
    "                           confidence_scaling_factor=confidence_scaling_factor,\n",
    "                           exploration_variance=exploration_variance,\n",
    "                           p=p,\n",
    "                           training_window=training_window,\n",
    "                           learning_rate=learning_rate,\n",
    "                           epochs=epochs,\n",
    "                           training_period=training_period,\n",
    "                           device=device\n",
    "                          )\n",
    "            \n",
    "            model.set_init_param(model.model.parameters()) # keep initial parameters for regularization\n",
    "        \n",
    "        ##TODO\n",
    "        \"\"\"\n",
    "        if lin_neural == Lin:\n",
    "            model = lin_neural(ucb_ts,\n",
    "                               bandit,\n",
    "                               reg_factor=reg_factor,\n",
    "                               delta=delta,\n",
    "                               confidence_scaling_factor=confidence_scaling_factor,\n",
    "                               exploration_variance=exploration_variance\n",
    "                              )\n",
    "        \"\"\"                \n",
    "        \n",
    "        model.run()\n",
    "        regrets[i] = np.cumsum(model.regrets.to('cpu').numpy())\n",
    "        np.cumsum(model.regrets.to('cpu').numpy())\n",
    "    if save: # save regrets\n",
    "        np.save('regrets/' + save, regrets)\n",
    "    return regrets    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDeUY26iZBNk"
   },
   "source": [
    "# Experiment A: (h, d, m) - Algorithm - Regret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxAGtJeFZBNO"
   },
   "source": [
    "### Bandit settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1612114630240,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "x2DzcHGzZBNO"
   },
   "outputs": [],
   "source": [
    "# T = 1000\n",
    "# n_sim = 20 # number of simulations\n",
    "\n",
    "n_arms = 20 # N\n",
    "n_features_default = 20 # d\n",
    "n_assortment = 4 # K\n",
    "n_samples = 30 # M, number of samples per each round and arm, for TS\n",
    "\n",
    "noise_std = 0.01 # noise of reward: xi = noise_std*N(0,1)\n",
    "\n",
    "\n",
    "def F(x): # round_reward_function\n",
    "    if x.dim == 1: # if x is a vector\n",
    "        return torch.sum(x)\n",
    "    else: # if x is a matrix\n",
    "        return torch.sum(x, dim=-1)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sugHGUJWZBNP"
   },
   "source": [
    "### Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 756,
     "status": "ok",
     "timestamp": 1612114633530,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "c9bthPvvZBNQ"
   },
   "outputs": [],
   "source": [
    "### reg_factor = 0.5 # lambda\n",
    "reg_factor = 2 # lambda\n",
    "delta = 0.1 # delta\n",
    "exploration_variance = 1 # nu, for TS and CombLinUCB\n",
    "confidence_scaling_factor = 1 # gamma, for CN-UCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0-F-FUjZBNQ"
   },
   "source": [
    "### Neural network settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1612114633902,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "2v72Wp28ZBNR"
   },
   "outputs": [],
   "source": [
    "hidden_size_default = 20 # m\n",
    "epochs = 100 # repeat training for each period\n",
    "training_period = 5 ### training period\n",
    "training_window = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "p = 0.0 # no dropout\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 617,
     "status": "ok",
     "timestamp": 1612114693709,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "9DEQ17WIZBNS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epEs02A1ZBNn"
   },
   "source": [
    "### (h1, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87wWdIdEZBNn",
    "outputId": "4d60e50d-e07c-4b67-fefb-aba635c1cf97"
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=10, hidden_size=20, save='reg_h1_CNUCB_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyfIV3PfZBNo"
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=10, hidden_size=20, save='reg_h1_CNTS_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTsyUhEYZBNo"
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=10, hidden_size=20, n_samples=10, save='reg_h1_CNTSOpt_20_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0sbFSlFZBNo"
   },
   "source": [
    "### (h2, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiZr0S_TZBNo"
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=20, hidden_size=20, save='reg_h2_CNUCB_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_MqelcKZBNo"
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=20, save='reg_h2_CNTS_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACMKDA72ZBNo"
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=20, n_samples=10, save='reg_h2_CNTSOpt_20_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPOILfGyZBNo"
   },
   "source": [
    "### (h3, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57gx8mwEZBNp"
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=20, hidden_size=20, save='reg_h3_CNUCB_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XXs2NziZBNp"
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=20, save='reg_h3_CNTS_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvTmEx7nZBNp"
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=20, n_samples=10, save='reg_h3_CNTSOpt_20_20')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4H9aXScLZBNk",
    "L_N_m7AFZBNl",
    "hJY9XrDLZBNm",
    "epEs02A1ZBNn",
    "d0sbFSlFZBNo",
    "NPOILfGyZBNo",
    "2kiLkgOmZBNp",
    "mWGIqRfhZBNq",
    "SltoRMfyZBNr",
    "1gmXsux9ZBNs",
    "tjXEJNxQZBNt",
    "zp9KsTdbZBNt",
    "QyQGIg1WZBNu",
    "adMLERWmZBNu",
    "fAOeYOEWZBNv",
    "ksgskGR_ZBNw",
    "3fdRizR9ZBNw",
    "pj9ZZ57TZBNx",
    "tzYUU36fZBNx",
    "A7mqTpA5ZBNy",
    "2nkj062kZBNz",
    "9lIDEjnVZBN0",
    "UD4tMhgyZBN1",
    "1vA-6tsGZBN2",
    "CR2mquYvZBN2",
    "oBjB2zifZBN3",
    "C2jEGbBLZBN3",
    "h86J_GTMZBN4",
    "aiKyZJj3ZBN5",
    "6M2w1wXTZBN5",
    "9KA0DHCzZBN6",
    "ct4UkKj2ZBN6",
    "KmFOyn3bZBN7",
    "GidF2tcVZBN7",
    "AY2N28SVZBN8",
    "_wC-xaoFZBN9",
    "qv82nCIRZBN9",
    "WXkandK1ZBN-",
    "TVKsvkbNZBN-",
    "mSHybzJ3ZBN_",
    "eQa6-hhRZBOA",
    "67icjm2_ZBOB",
    "B1IrNW0XZBOB"
   ],
   "name": "Copy of Experiments-ver3.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/DurianFarmer/combinatorial_neural_bandits/blob/master/Experiments-ver3.ipynb",
     "timestamp": 1612112504266
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
