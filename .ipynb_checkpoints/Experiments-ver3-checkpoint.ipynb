{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "import abc\n",
    "\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from codes import *\n",
    "\n",
    "if not os.path.exists('regrets'):\n",
    "    os.mkdir('regrets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandit settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2000\n",
    "n_sim = 10 # number of simulations\n",
    "\n",
    "\n",
    "n_arms = 12 # N\n",
    "n_features_default = 20 # d\n",
    "n_assortment = 4 # K\n",
    "n_samples = 50 # M, number of samples per each round and arm, for TS\n",
    "\n",
    "noise_std = 0.01 # noise of reward: xi = noise_std*N(0,1)\n",
    "\n",
    "\n",
    "def F(x): # round_reward_function\n",
    "    if x.dim == 1: # if x is a vector\n",
    "        return torch.sum(x)\n",
    "    else: # if x is a matrix\n",
    "        return torch.sum(x, dim=-1)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_factor = 1 # lambda\n",
    "delta = 0.1 # delta\n",
    "exploration_variance = 0.8 # nu, for TS and CombLinUCB\n",
    "confidence_scaling_factor = 1 # gamma, for CN-UCB, gamma is larger than nu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size_default = 20 # m\n",
    "epochs = 100 # repeat training for each period\n",
    "training_period = 5 ### training period\n",
    "training_window = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "p = 0.0 # no dropout\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment descirption\n",
    "### Hidden functions\n",
    "- Linear: $h_{1}(\\mathbf{x}_{t,i}) = \\mathbf{x}_{t,i}^{\\top}\\mathbf{a}$\n",
    "- Quadratic: $h_{2}(\\mathbf{x}_{t,i}) = (\\mathbf{x}_{t,i}^{\\top}\\mathbf{a})^{2}$\n",
    "- Non-linear: $h_{3}(\\mathbf{x}_{t,i}) = \\cos(\\pi \\mathbf{x}_{t,i}^{\\top}\\mathbf{a})$\n",
    "- where $\\mathbf{a} \\sim U(-1,1)/\\|\\mathbf{a}\\|_{2}$\n",
    "\n",
    "### For each hidden function, compare the following algorithms\n",
    "- CombLinUCB\n",
    "- CombLinTS\n",
    "- CN-UCB\n",
    "- CN-TS(1): single reward sample\n",
    "- CN-TS(30): optimistic sampling, sample size = 30 (default sample size is 1)\n",
    "\n",
    "### Ablation study of feature dimension *d* and neural network width *m*\n",
    "- Default value: $d = 20, m = 20$\n",
    "- $d = \\{20, 40\\}$  for all algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden function, bandit, learning algorithm and regret settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = \"h1\"\n",
    "h2 = \"h2\"\n",
    "h3 = \"h3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hidden function\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "n_features = 20\n",
    "hidden_size = 40\n",
    "h_str = \"h1\"\n",
    "\n",
    "tmp = np.random.uniform(low=-1.0, high=1.0, size=n_features)\n",
    "a = torch.from_numpy(tmp / np.linalg.norm(tmp, ord=2)).to(device)\n",
    "\n",
    "if h_str == \"h1\":\n",
    "    def h(x):\n",
    "        return torch.dot(x, a).to(device)    \n",
    "elif h_str == \"h2\":\n",
    "    def h(x):\n",
    "        return (torch.dot(x, a)**2).to(device)    \n",
    "elif h_str == \"h3\":\n",
    "    def h(x):\n",
    "        return torch.cos(torch.pi*np.dot(x, a)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0461, 0.4024])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit():\n",
    "    def __init__(self,\n",
    "                 T,\n",
    "                 n_arms,                 \n",
    "                 n_features,                                  \n",
    "                 h,                                                   \n",
    "                 noise_std=1.0,                 \n",
    "                 n_assortment=1,\n",
    "                 n_samples=1,\n",
    "                 round_reward_function=sum,\n",
    "                 device=torch.device('cpu')\n",
    "                ):\n",
    "        # number of rounds\n",
    "        self.T = T\n",
    "        # number of arms\n",
    "        self.n_arms = n_arms\n",
    "        # number of features for each arm\n",
    "        self.n_features = n_features        \n",
    "        \n",
    "        # average reward function\n",
    "        # h : R^d -> R\n",
    "        self.h = h\n",
    "\n",
    "        # standard deviation of Gaussian reward noise\n",
    "        self.noise_std = noise_std\n",
    "        \n",
    "        # number of assortment (top-K)\n",
    "        self.n_assortment = n_assortment                \n",
    "        \n",
    "        # (TS) number of samples for each round and arm\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "        # round reward function\n",
    "        self.round_reward_function = round_reward_function                \n",
    "        \n",
    "        # device\n",
    "        self.device = device\n",
    "        \n",
    "        # generate random features\n",
    "        self.reset()\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def arms(self):\n",
    "        \"\"\"Return [0, ...,n_arms-1]\n",
    "        \"\"\"\n",
    "        return range(self.n_arms)\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Generate new features and new rewards.\n",
    "        \"\"\"\n",
    "        self.reset_features()\n",
    "        self.reset_rewards()\n",
    "\n",
    "    def reset_features(self):\n",
    "        \"\"\"Generate normalized random N(0,1) features.\n",
    "        \"\"\"        \n",
    "        x = np.random.randn(self.T, self.n_arms, self.n_features)\n",
    "        x /= np.repeat(np.linalg.norm(x, axis=-1, ord=2), self.n_features).reshape(self.T, self.n_arms, self.n_features)\n",
    "        self.features = torch.from_numpy(x).to(self.device)\n",
    "\n",
    "    def reset_rewards(self):\n",
    "        \"\"\"Generate rewards for each arm and each round,\n",
    "        following the reward function h + Gaussian noise.\n",
    "        \"\"\"            \n",
    "        self.rewards = torch.Tensor(\n",
    "            [\n",
    "                self.h( self.features[t, k] ) + self.noise_std*torch.randn(1).to(self.device)\\\n",
    "                for t,k in itertools.product(range(self.T), range(self.n_arms))\n",
    "            ]\n",
    "        ).reshape(self.T, self.n_arms)\n",
    "\n",
    "        ## to be used only to compute regret, NOT by the algorithm itself        \n",
    "        a = self.rewards.to(torch.device('cpu')).numpy()\n",
    "        ind = np.argpartition(a, -1*self.n_assortment, axis=1)[:,-1*self.n_assortment:]        \n",
    "        s_ind = np.array([list(ind[i][np.argsort(a[i][ind[i]])][::-1]) for i in range(0, np.shape(a)[0])])\n",
    "        \n",
    "        self.best_super_arm = torch.from_numpy(s_ind).to(self.device)\n",
    "        self.best_rewards = torch.Tensor([a[i][s_ind[i]] for i in range(0,np.shape(a)[0])]).to(self.device)\n",
    "        self.best_round_reward = self.round_reward_function(self.best_rewards).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Bandit\n",
    "bandit = Bandit(T,\n",
    "              n_arms,\n",
    "              n_features, \n",
    "              h=h,\n",
    "              noise_std=noise_std,\n",
    "              n_assortment=n_assortment,\n",
    "              n_samples=n_samples,\n",
    "              round_reward_function=F,\n",
    "              device=device\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning algorithm and regret\n",
    "regrets = torch.empty((n_sim, T)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for combinatorial bandits\n",
    "def inv_sherman_morrison_iter(a, A_inv):\n",
    "    \"\"\"Inverse of a matrix for combinatorial case.\n",
    "    \"\"\"\n",
    "    temp = A_inv    \n",
    "    for u in a:                     \n",
    "        Au = torch.matmul(temp, u)\n",
    "        temp = temp - torch.ger(Au, Au)/(1+torch.matmul(u.T, Au))    \n",
    "    return temp       \n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Template for fully connected neural network for scalar approximation.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_size=1, \n",
    "                 hidden_size=2,\n",
    "                 n_layers=1,\n",
    "                 activation='ReLU',\n",
    "                 p=0.0,\n",
    "                ):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        if self.n_layers == 1:\n",
    "            self.layers = [nn.Linear(input_size, 1)]                        \n",
    "        else:\n",
    "            size  = [input_size] + [hidden_size,] * (self.n_layers-1) + [1]\n",
    "            ##\n",
    "            self.layers = [nn.Linear(size[i], size[i+1], bias=False) \\\n",
    "                           for i in range(self.n_layers)]\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "        \n",
    "        # activation function\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == 'ReLU':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'LeakyReLU':\n",
    "            self.activation = nn.LeakyReLU(negative_slope=0.1)\n",
    "        else:\n",
    "            raise Exception('{} not an available activation'.format(activation))\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_layers-1):\n",
    "            x = self.dropout(self.activation(self.layers[i](x)))\n",
    "        x = self.layers[-1](x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MyUCB_TS(abc.ABC):\n",
    "    \"\"\"Base class for UCB and TS methods.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ucb_ts, ## A string. \"UCB\" for UCB, \"TS\" for TS\n",
    "                 bandit,\n",
    "                 reg_factor=1.0,\n",
    "                 confidence_scaling_factor=1, ## for UCB, gamma\n",
    "                 exploration_variance=1, ## for TS, nu\n",
    "                 delta=0.1,\n",
    "                 training_period=1,\n",
    "                 throttle=int(1e2),\n",
    "                 device=torch.device('cpu')\n",
    "                ):\n",
    "        ## select whether UCB or TS\n",
    "        self.ucb_ts = ucb_ts\n",
    "        # bandit object, contains features and generated rewards\n",
    "        self.bandit = bandit\n",
    "        # L2 regularization strength\n",
    "        self.reg_factor = reg_factor\n",
    "        # Confidence bound with probability 1-delta\n",
    "        self.delta = delta\n",
    "\n",
    "        # multiplier for the confidence bound            \n",
    "        self.confidence_scaling_factor = confidence_scaling_factor\n",
    "\n",
    "        # exploration variance for TS\n",
    "        self.exploration_variance = exploration_variance\n",
    "        \n",
    "        # train approximator only few rounds\n",
    "        self.training_period = training_period\n",
    "        \n",
    "        # throttle tqdm updates\n",
    "        self.throttle = throttle\n",
    "        \n",
    "        # device\n",
    "        self.device = device\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    ## for UCB\n",
    "    def reset_upper_confidence_bounds(self):\n",
    "        \"\"\"Initialize upper confidence bounds and related quantities.\n",
    "        \"\"\"\n",
    "        if self.ucb_ts == \"UCB\":\n",
    "            self.exploration_bonus = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.mu_hat = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.upper_confidence_bounds = torch.ones((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    ## for TS\n",
    "    def reset_sample_rewards(self):\n",
    "        \"\"\"Initialize sample rewards and related quantities.\n",
    "        \"\"\"\n",
    "        if self.ucb_ts == \"TS\":\n",
    "            self.sigma_square = torch.ones((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.mu_hat = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.sample_rewards = torch.zeros((self.bandit.T, self.bandit.n_arms, self.bandit.n_samples)).to(self.device)\n",
    "            self.optimistic_sample_rewards = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def reset_regrets(self):\n",
    "        \"\"\"Initialize regrets.\n",
    "        \"\"\"\n",
    "        self.regrets = torch.zeros(self.bandit.T).to(self.device)\n",
    "\n",
    "    def reset_actions(self):\n",
    "        \"\"\"Initialize cache of actions (actions: played set of arms of each round).\n",
    "        \"\"\"\n",
    "        self.actions = torch.zeros((self.bandit.T, self.bandit.n_assortment)).to(self.device)\n",
    "    \n",
    "    def reset_A_inv(self):\n",
    "        \"\"\"Initialize n_arms square matrices representing the inverses\n",
    "        of exploration bonus matrices.\n",
    "        \"\"\"\n",
    "        self.A_inv = torch.eye(self.approximator_dim).to(self.device)/self.reg_factor        \n",
    "    \n",
    "    def reset_grad_approx(self):\n",
    "        \"\"\"Initialize the gradient of the approximator w.r.t its parameters.\n",
    "        \"\"\"\n",
    "        self.grad_approx = torch.zeros((self.bandit.n_arms, self.approximator_dim)).to(self.device)\n",
    "        \n",
    "    def sample_action(self):        \n",
    "        \"\"\"Return the action (set of arms) to play based on current estimates\n",
    "        \"\"\"\n",
    "        ## for UCB\n",
    "        if self.ucb_ts == \"UCB\":\n",
    "            a = self.upper_confidence_bounds[self.iteration].to(torch.device('cpu')).numpy()\n",
    "        ## for TS\n",
    "        if self.ucb_ts == \"TS\":\n",
    "            a = self.optimistic_sample_rewards[self.iteration].to(torch.device('cpu')).numpy()\n",
    "\n",
    "        ind = np.argpartition(a, -1*self.bandit.n_assortment)[-1*self.bandit.n_assortment:]\n",
    "        s_ind = ind[np.argsort(a[ind])][::-1]\n",
    "        return torch.Tensor(s_ind.copy()).to(self.device)               \n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def reset(self):\n",
    "        \"\"\"Initialize variables of interest.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def approximator_dim(self):\n",
    "        \"\"\"Number of parameters used in the approximator.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def confidence_multiplier(self):\n",
    "        \"\"\"Multiplier for the confidence exploration bonus.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def update_confidence_bounds(self):\n",
    "        \"\"\"Update the confidence bounds for all arms at time t.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update_output_gradient(self):\n",
    "        \"\"\"Compute output gradient of the approximator w.r.t its parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def train(self):\n",
    "        \"\"\"Update approximator.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def predict(self):\n",
    "        \"\"\"Predict rewards based on an approximator.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    ## for UCB\n",
    "    def update_confidence_bounds(self):\n",
    "        \"\"\"Update confidence bounds and related quantities for all set of arms.\n",
    "        \"\"\"\n",
    "        # update self.grad_approx\n",
    "        self.update_output_gradient()\n",
    "        \n",
    "        # UCB exploration bonus\n",
    "        self.exploration_bonus[self.iteration] = torch.Tensor(\n",
    "            [\n",
    "                self.confidence_multiplier * torch.sqrt(torch.dot(self.grad_approx[a], torch.matmul(self.A_inv, self.grad_approx[a].T))) for a in self.bandit.arms\n",
    "            ]\n",
    "        )        \n",
    "        \n",
    "        # update reward prediction mu_hat\n",
    "        self.predict()\n",
    "        \n",
    "        # estimated combined bound for reward\n",
    "        self.upper_confidence_bounds[self.iteration] = self.mu_hat[self.iteration] + self.exploration_bonus[self.iteration]\n",
    "\n",
    "    ## for TS\n",
    "    def update_sample_rewards(self):\n",
    "        \"\"\"Update sample rewards and related quantities for all set of arms.\n",
    "        \"\"\"        \n",
    "        # update self.grad_approx\n",
    "        self.update_output_gradient() \n",
    "        \n",
    "        # update sigma_square        \n",
    "        self.sigma_square[self.iteration] = [self.reg_factor * \\\n",
    "                                             torch.dot(self.grad_approx[a], torch.matmul(self.A_inv, self.grad_approx[a].T)) \\\n",
    "                                             for a in self.bandit.arms]\n",
    "                \n",
    "        # update reward prediction mu_hat\n",
    "        self.predict()\n",
    "        \n",
    "        # update sample reward\n",
    "        self.sample_rewards[self.iteration] = [torch.random.normal(loc = self.mu_hat[self.iteration, a], \\\n",
    "                                                                scale = (self.exploration_variance**2) * self.sigma_square[self.iteration, a], \\\n",
    "                                                                size = self.bandit.n_samples) \\\n",
    "                                               for a in self.bandit.arms]        \n",
    "        \n",
    "        # update optimistic sample reward for each arm\n",
    "        self.optimistic_sample_rewards[self.iteration] = torch.max(self.sample_rewards[self.iteration], dim=-1)\n",
    "        \n",
    "    def update_A_inv(self):\n",
    "        \"\"\"Update A_inv by using an iteration of Sherman_Morrison formula\n",
    "        \"\"\"\n",
    "        self.A_inv = inv_sherman_morrison_iter(\n",
    "            self.grad_approx[self.action.numpy()],\n",
    "            self.A_inv\n",
    "        )               \n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"Run an episode of bandit.\n",
    "        \"\"\"\n",
    "        postfix = {\n",
    "            'total regret': 0.0,\n",
    "            '% optimal set of arms': 0.0,\n",
    "        }\n",
    "        with tqdm(total=self.bandit.T, postfix=postfix) as pbar:\n",
    "            for t in range(self.bandit.T):                \n",
    "                ## for UCB\n",
    "                if self.ucb_ts == \"UCB\":\n",
    "                    # update confidence of all set of arms based on observed features at time t\n",
    "                    self.update_confidence_bounds()\n",
    "                ## for TS\n",
    "                if self.ucb_ts == \"TS\":\n",
    "                    ## update sample rewards of all set of arms based on observed features at time t\n",
    "                    self.update_sample_rewards()                \n",
    "                \n",
    "                # pick action (set of arm) with the highest boosted estimated reward\n",
    "                self.action = self.sample_action()\n",
    "                self.actions[t] = self.action\n",
    "                # update approximator                          \n",
    "                self.train() ### lin and neural training are different\n",
    "                # update exploration indicator A_inv\n",
    "                self.update_A_inv()\n",
    "                \n",
    "                ## compute regret                \n",
    "                self.regrets[t] = self.bandit.best_round_reward[t] - self.bandit.round_reward_function(self.bandit.rewards[t, self.action.numpy()])                 \n",
    "                \n",
    "                # increment counter\n",
    "                self.iteration += 1\n",
    "                \n",
    "                # log\n",
    "                postfix['total regret'] += self.regrets[t].numpy()\n",
    "                n_optimal_arm = np.sum(\n",
    "                    np.prod(\n",
    "                        (self.actions[:self.iteration].numpy()==self.bandit.best_super_arm[:self.iteration].numpy())*1, \n",
    "                        axis=1)                                                          \n",
    "                )\n",
    "                postfix['% optimal set of arms'] = '{:.2%}'.format(n_optimal_arm / self.iteration)\n",
    "                \n",
    "                if t % self.throttle == 0:\n",
    "                    pbar.set_postfix(postfix)\n",
    "                    pbar.update(self.throttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeural(MyUCB_TS):\n",
    "    \"\"\"CN-UCB or CN-TS.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ucb_ts, ## A string. \"UCB\" for UCB, \"TS\" for TS\n",
    "                 bandit,\n",
    "                 hidden_size=20,\n",
    "                 n_layers=2,\n",
    "                 reg_factor=1.0,\n",
    "                 delta=0.01,\n",
    "                 confidence_scaling_factor=1, ## for UCB\n",
    "                 exploration_variance=1, ## for TS\n",
    "                 training_window=100,\n",
    "                 p=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 epochs=1,\n",
    "                 training_period=1,\n",
    "                 throttle=1,\n",
    "                 device=torch.device('cpu'),\n",
    "                ):\n",
    "\n",
    "        # hidden size of the NN layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # number of layers\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # number of rewards in the training buffer\n",
    "        self.training_window = training_window\n",
    "        \n",
    "        # NN parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.device = device\n",
    "            \n",
    "        # dropout rate\n",
    "        self.p = p\n",
    "\n",
    "        # neural network\n",
    "        self.model = Model(input_size=bandit.n_features, \n",
    "                           hidden_size=self.hidden_size,\n",
    "                           n_layers=self.n_layers,\n",
    "                           p=self.p\n",
    "                          ).to(self.device)        \n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        super().__init__(ucb_ts,\n",
    "                         bandit, \n",
    "                         reg_factor=reg_factor,\n",
    "                         confidence_scaling_factor=confidence_scaling_factor, ## for UCB\n",
    "                         exploration_variance=exploration_variance, ## for TS\n",
    "                         delta=delta,\n",
    "                         throttle=throttle,\n",
    "                         training_period=training_period,\n",
    "                         device=self.device\n",
    "                        )\n",
    "\n",
    "    @property\n",
    "    def approximator_dim(self):\n",
    "        \"\"\"Sum of the dimensions of all trainable layers in the network.\n",
    "        \"\"\"\n",
    "        return sum(w.numel() for w in self.model.parameters() if w.requires_grad)\n",
    "    \n",
    "    @property\n",
    "    def confidence_multiplier(self):\n",
    "        \"\"\"Constant equal to confidence_scaling_factor\n",
    "        \"\"\"\n",
    "        return self.confidence_scaling_factor\n",
    "    \n",
    "    def update_output_gradient(self):\n",
    "        \"\"\"Get gradient of network prediction w.r.t network weights.\n",
    "        \"\"\"\n",
    "        for a in self.bandit.arms:\n",
    "            x = torch.FloatTensor(\n",
    "                self.bandit.features[self.iteration, a].reshape(1,-1).float()\n",
    "            ).to(self.device)\n",
    "            \n",
    "            self.model.zero_grad()\n",
    "            y = self.model(x)\n",
    "            y.backward()\n",
    "                        \n",
    "            self.grad_approx[a] = torch.cat([\n",
    "                w.grad.detach().flatten() / np.sqrt(self.hidden_size)\n",
    "                for w in self.model.parameters() if w.requires_grad]\n",
    "            ).to(self.device)\n",
    "            \n",
    "            \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal estimates.\n",
    "        \"\"\"\n",
    "        self.reset_upper_confidence_bounds() ## for UCB\n",
    "        self.reset_sample_rewards() ## for TS\n",
    "        self.reset_regrets()\n",
    "        self.reset_actions()\n",
    "        self.reset_A_inv()\n",
    "        self.reset_grad_approx()\n",
    "        self.iteration = 0\n",
    "\n",
    "    ## inital parameters\n",
    "    def set_init_param(self, parameters):\n",
    "        self.init_param = self.param_to_tensor(parameters)\n",
    "\n",
    "    ## torch Parameter object to Tensor object\n",
    "    def param_to_tensor(self, parameters):\n",
    "        a = torch.empty(1).to(self.device)\n",
    "        for p in parameters:\n",
    "            a = torch.cat((a, p.data.flatten()))\n",
    "        return a[1:].to(self.device)    \n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Train neural approximator.        \n",
    "        \"\"\"\n",
    "        ### train only when training_period occurs\n",
    "        if self.iteration % self.training_period == 0:                        \n",
    "            iterations_so_far = range(np.max([0, self.iteration-self.training_window]), self.iteration+1)\n",
    "            actions_so_far = self.actions[np.max([0, self.iteration-self.training_window]):self.iteration+1].numpy() # this is a matrix            \n",
    "\n",
    "            temp = torch.cat([self.bandit.features[t, actions_so_far[i]] for i, t in enumerate(iterations_so_far)])\n",
    "            x_train = torch.FloatTensor( torch.reshape(temp, (1,-1,self.bandit.n_features)).squeeze().float() ).to(self.device)\n",
    "\n",
    "            temp = torch.cat([self.bandit.rewards[t, actions_so_far[i]] for i, t in enumerate(iterations_so_far)])\n",
    "            y_train = torch.FloatTensor( torch.reshape(temp, (1,-1)).squeeze().float() ).to(self.device)               \n",
    "\n",
    "            # train mode\n",
    "            self.model.train()\n",
    "            for _ in range(self.epochs):\n",
    "                ## computing the regularization parameter\n",
    "                tmp = (self.param_to_tensor(self.model.parameters()) - self.init_param).to(torch.device('cpu')).numpy()\n",
    "                param_diff = np.linalg.norm(tmp)\n",
    "                regularization = (self.reg_factor*self.hidden_size*param_diff**2)/2\n",
    "\n",
    "                ## update weight\n",
    "                y_pred = self.model.forward(x_train).squeeze()            \n",
    "                ### loss = nn.MSELoss()(y_train, y_pred)\n",
    "                loss = nn.MSELoss(reduction='sum')(y_train, y_pred)/2 + regularization            \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        else:\n",
    "            pass\n",
    "                                        \n",
    "    def predict(self):\n",
    "        \"\"\"Predict reward.\n",
    "        \"\"\"\n",
    "        # eval mode\n",
    "        self.model.eval()        \n",
    "        self.mu_hat[self.iteration] = self.model.forward(torch.FloatTensor( self.bandit.features[self.iteration].float() )).detach().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2000 [00:00<?, ?it/s, % optimal set of arms=0, total regret=0]"
     ]
    }
   ],
   "source": [
    "for i in range(n_sim):\n",
    "    bandit.reset_rewards()\n",
    "    \n",
    "    model = MyNeural(\"UCB\",\n",
    "                   bandit,\n",
    "                   hidden_size,\n",
    "                   reg_factor=reg_factor,\n",
    "                   delta=delta,\n",
    "                   confidence_scaling_factor=confidence_scaling_factor,\n",
    "                   exploration_variance=exploration_variance,\n",
    "                   p=p,\n",
    "                   training_window=training_window,\n",
    "                   learning_rate=learning_rate,\n",
    "                   epochs=epochs,\n",
    "                   training_period=training_period,\n",
    "                   device=device\n",
    "                  )\n",
    "    model.set_init_param(model.model.parameters()) # keep initial parameters for regularization\n",
    "    \n",
    "    model.run()\n",
    "    regrets[i] = torch.cumsum(model.regrets)\n",
    "\n",
    "result = regrets.to('cpu').numpy()\n",
    "if save: # save regrets\n",
    "    np.save('regrets/' + save, result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.3333, 0.5000],\n",
       "        [0.6667, 0.8333, 1.0000]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "tt/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(n_sim):\n",
    "    bandit.reset_rewards()\n",
    "\n",
    "    if lin_neural == Neural:\n",
    "        model = lin_neural(ucb_ts,\n",
    "                           bandit,\n",
    "                           hidden_size,\n",
    "                           reg_factor=reg_factor,\n",
    "                           delta=delta,\n",
    "                           confidence_scaling_factor=confidence_scaling_factor,\n",
    "                           exploration_variance=exploration_variance,\n",
    "                           p=p,\n",
    "                           training_window=training_window,\n",
    "                           learning_rate=learning_rate,\n",
    "                           epochs=epochs,\n",
    "                           training_period=training_period,\n",
    "                           use_cuda=use_cuda\n",
    "                          )\n",
    "\n",
    "        model.set_init_param(model.model.parameters()) # keep initial parameters for regularization\n",
    "\n",
    "    if lin_neural == Lin:\n",
    "        model = lin_neural(ucb_ts,\n",
    "                           bandit,\n",
    "                           reg_factor=reg_factor,\n",
    "                           delta=delta,\n",
    "                           confidence_scaling_factor=confidence_scaling_factor,\n",
    "                           exploration_variance=exploration_variance\n",
    "                          )\n",
    "\n",
    "    model.run()\n",
    "    regrets[i] = torch.cumsum(model.regrets)\n",
    "\n",
    "result = regrets.to('cpu').numpy()\n",
    "if save: # save regrets\n",
    "    np.save('regrets/' + save, result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(lin_neural, ucb_ts, h_str, n_features=20, hidden_size=100, n_samples=1, save = ''):\n",
    "    \"\"\" kind explanation\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Hidden function\n",
    "    SEED = 1234\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    tmp = np.random.uniform(low=-1.0, high=1.0, size=n_features)\n",
    "    a = torch.from_numpy(tmp / np.linalg.norm(tmp, ord=2)).to(device)\n",
    "    \n",
    "    if h_str == \"h1\":\n",
    "        h = lambda x: torch.dot(x, a)\n",
    "        ###h = lambda x: 100*np.dot(x, a)\n",
    "    elif h_str == \"h2\":\n",
    "        h = lambda x: torch.dot(x, a)**2\n",
    "        ###h = lambda x: 100*np.dot(x, a)**2\n",
    "    elif h_str == \"h3\":\n",
    "        h = lambda x: torch.cos(torch.pi*np.dot(x, a))\n",
    "        ###h = lambda x: 100*np.cos(np.pi*np.dot(x, a))\n",
    "    \n",
    "    ## Bandit\n",
    "    bandit = ContextualBandit(T,\n",
    "                              n_arms,\n",
    "                              n_features, \n",
    "                              h,\n",
    "                              noise_std=noise_std,\n",
    "                              n_assortment=n_assortment,\n",
    "                              n_samples=n_samples,\n",
    "                              round_reward_function=F,\n",
    "                              device=device\n",
    "                             )\n",
    "    \n",
    "    ## Learning algorithm and regret\n",
    "    regrets = torch.empty((n_sim, T)).to(device)\n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        bandit.reset_rewards()\n",
    "        \n",
    "        if lin_neural == Neural:\n",
    "            model = lin_neural(ucb_ts,\n",
    "                               bandit,\n",
    "                               hidden_size=hidden_size,\n",
    "                               reg_factor=reg_factor,\n",
    "                               delta=delta,\n",
    "                               confidence_scaling_factor=confidence_scaling_factor,\n",
    "                               exploration_variance=exploration_variance,\n",
    "                               p=p,\n",
    "                               training_window=training_window,\n",
    "                               learning_rate=learning_rate,\n",
    "                               epochs=epochs,\n",
    "                               training_period=training_period,\n",
    "                               use_cuda=use_cuda\n",
    "                              )\n",
    "            \n",
    "            model.set_init_param(model.model.parameters()) # keep initial parameters for regularization\n",
    "            \n",
    "        if lin_neural == Lin:\n",
    "            model = lin_neural(ucb_ts,\n",
    "                               bandit,\n",
    "                               reg_factor=reg_factor,\n",
    "                               delta=delta,\n",
    "                               confidence_scaling_factor=confidence_scaling_factor,\n",
    "                               exploration_variance=exploration_variance\n",
    "                              )\n",
    "        \n",
    "        model.run()\n",
    "        regrets[i] = torch.cumsum(model.regrets)\n",
    "    \n",
    "    result = regrets.to('cpu').numpy()\n",
    "    if save: # save regrets\n",
    "        np.save('regrets/' + save, result)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment A: (h, d, m) - Algorithm - Regret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 40, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sim = 1\n",
    "T = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7c3411ea479b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeural\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"UCB\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg_h1_CNUCB_80_40'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-a81d7f220858>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(lin_neural, ucb_ts, h_str, n_features, hidden_size, n_samples, save)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m## Bandit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     bandit = ContextualBandit(T,\n\u001b[0m\u001b[1;32m     24\u001b[0m                               \u001b[0mn_arms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                               \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/codes/bandit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, T, n_arms, n_features, h, noise_std, n_assortment, n_samples, round_reward_function, device)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# generate random features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/codes/bandit.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \"\"\"\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_rewards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/codes/bandit.py\u001b[0m in \u001b[0;36mreset_rewards\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m         tmp = np.array(\n\u001b[0;32m---> 74\u001b[0;31m             [\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_std\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_arms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/codes/bandit.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m         tmp = np.array(\n\u001b[1;32m     74\u001b[0m             [\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_std\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_arms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             ]\n",
      "\u001b[0;32m<ipython-input-9-a81d7f220858>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh_str\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"h1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m###h = lambda x: 100*np.dot(x, a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mh_str\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"h2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=40, hidden_size=20, save='reg_h1_CNUCB_80_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 220/500 [00:23<00:29,  9.47it/s, total regret=14.3, % optimal set of arms=20.45%]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-17969719bd58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeural\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg_h1_CNTS_80_40'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-117-7be3733ac0b8>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(lin_neural, ucb_ts, h_str, n_features, hidden_size, n_samples, save)\u001b[0m\n\u001b[1;32m     64\u001b[0m                               )\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mregrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregrets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/module_space/ucb_ts.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### lin and neural training are different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# update exploration indicator A_inv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_A_inv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;31m## compute regret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/module_space/ucb_ts.py\u001b[0m in \u001b[0;36mupdate_A_inv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"Update A_inv by using an iteration of Sherman_Morrison formula\n\u001b[1;32m    196\u001b[0m         \"\"\"\n\u001b[0;32m--> 197\u001b[0;31m         self.A_inv = inv_sherman_morrison_iter(\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_approx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_inv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/module_space/utils.py\u001b[0m in \u001b[0;36minv_sherman_morrison_iter\u001b[0;34m(a, A_inv)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mAu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mouter\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mouter\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=40, hidden_size=40, save='reg_h1_CNTS_80_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=80, hidden_size=40, n_samples=50, save='reg_h1_CNTSOpt_40_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 40, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:31<00:00, 21.76it/s, total regret=61.2, % optimal set of arms=7.00%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=40, hidden_size=20, save='reg_h2_CNUCB_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:27<00:00, 22.83it/s, total regret=49.6, % optimal set of arms=6.35%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=40, hidden_size=20, save='reg_h2_CNTS_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 1070/2000 [00:46<00:40, 22.86it/s, total regret=30.8, % optimal set of arms=6.64%]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-b609e7cedfd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeural\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg_h2_CNTSOpt_40_20'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-163-7be3733ac0b8>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(lin_neural, ucb_ts, h_str, n_features, hidden_size, n_samples, save)\u001b[0m\n\u001b[1;32m     64\u001b[0m                               )\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mregrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregrets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/module_space/ucb_ts.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# update approximator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### lin and neural training are different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# update exploration indicator A_inv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_A_inv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/module_space/neural.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;31m## update weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;31m### loss = nn.MSELoss()(y_train, y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/combinatorial_neural_bandits/module_space/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         for hook in itertools.chain(\n\u001b[0m\u001b[1;32m    712\u001b[0m                 \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 self._forward_pre_hooks.values()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=40, hidden_size=20, n_samples=50, save='reg_h2_CNTSOpt_40_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 40, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:35<00:00, 20.89it/s, total regret=291, % optimal set of arms=0.20%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=40, hidden_size=20, save='reg_h3_CNUCB_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:35<00:00, 21.02it/s, total regret=322, % optimal set of arms=0.20%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=40, hidden_size=20, save='reg_h3_CNTS_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:31<00:00, 21.86it/s, total regret=283, % optimal set of arms=0.15%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=40, hidden_size=20, n_samples=50, save='reg_h3_CNTSOpt_40_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:11<00:00, 28.03it/s, total regret=16.8, % optimal set of arms=59.35%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=10, hidden_size=20, save='reg_h1_CNUCB_10_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=10, hidden_size=20, save='reg_h1_CNTS_10_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=10, hidden_size=20, n_samples=50, save='reg_h1_CNTSOpt_10_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=20, hidden_size=20, save='reg_h2_CNUCB_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=20, save='reg_h2_CNTS_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=20, n_samples=50, save='reg_h2_CNTSOpt_20_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=20, hidden_size=20, save='reg_h3_CNUCB_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=20, save='reg_h3_CNTS_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=20, n_samples=50, save='reg_h3_CNTSOpt_20_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombLinUCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h1, n_features=20, save='reg_h1_CombLinUCB_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h2, n_features=20, save='reg_h2_CombLinUCB_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h3, n_features=20, save='reg_h3_CombLinUCB_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h1, n_features=40, save='reg_h1_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h2, n_features=40, save='reg_h2_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h3, n_features=40, save='reg_h3_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombLinTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h1, n_features=20, save='reg_h1_CombLinTS_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h2, n_features=20, save='reg_h2_CombLinTS_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h3, n_features=20, save='reg_h3_CombLinTS_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h1, n_features=40, save='reg_h1_CombLinTS_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h2, n_features=40, save='reg_h2_CombLinTS_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h3, n_features=40, save='reg_h3_CombLinTS_40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 80, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=80, hidden_size=20, save='reg_h1_CNUCB_80_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=80, hidden_size=20, save='reg_h1_CNTS_80_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=80, hidden_size=20, n_samples=50, save='reg_h1_CNTSOpt_80_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 80, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=80, hidden_size=20, save='reg_h2_CNUCB_80_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=80, hidden_size=20, save='reg_h2_CNTS_80_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=80, hidden_size=20, n_samples=50, save='reg_h2_CNTSOpt_80_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 80, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=80, hidden_size=20, save='reg_h3_CNUCB_80_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=80, hidden_size=20, save='reg_h3_CNTS_80_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=80, hidden_size=20, save='reg_h3_CNTSOpt_80_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 40, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=40, hidden_size=20, save='reg_h1_CNUCB_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=40, hidden_size=20, save='reg_h1_CNTS_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=40, hidden_size=20, n_samples=50, save='reg_h1_CNTSOpt_40_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 40, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=40, hidden_size=20, save='reg_h2_CNUCB_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=40, hidden_size=20, save='reg_h2_CNTS_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=40, hidden_size=20, n_samples=50, save='reg_h2_CNTSOpt_40_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 40, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=40, hidden_size=20, save='reg_h3_CNUCB_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=40, hidden_size=20, save='reg_h3_CNTS_40_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=40, hidden_size=20, n_samples=50, save='reg_h3_CNTSOpt_40_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 20, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=20, hidden_size=60, save='reg_h1_CNUCB_20_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=60, save='reg_h1_CNTS_20_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=60, n_samples=50, save='reg_h1_CNTSOpt_20_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 20, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=20, hidden_size=60, save='reg_h2_CNUCB_20_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=60, save='reg_h2_CNTS_20_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=60, n_samples=50, save='reg_h2_CNTSOpt_20_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 20, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=20, hidden_size=60, save='reg_h3_CNUCB_20_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=60, save='reg_h3_CNTS_20_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=60, n_samples=50, save='reg_h3_CNTSOpt_20_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 60, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=60, hidden_size=60, save='reg_h1_CNUCB_60_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=60, hidden_size=60, save='reg_h1_CNTS_60_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=60, hidden_size=60, n_samples=50, save='reg_h1_CNTSOpt_60_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 60, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=60, hidden_size=60, save='reg_h2_CNUCB_60_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=60, hidden_size=60, save='reg_h2_CNTS_60_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=60, hidden_size=60, n_samples=50, save='reg_h2_CNTSOpt_60_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 60, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=60, hidden_size=60, save='reg_h3_CNUCB_60_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=60, hidden_size=60, save='reg_h3_CNTS_60_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=60, hidden_size=60, n_samples=50, save='reg_h3_CNTSOpt_60_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombLinUCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h1, n_features=20, save='reg_h1_CombLinUCB_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h2, n_features=20, save='reg_h2_CombLinUCB_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h3, n_features=20, save='reg_h3_CombLinUCB_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h1, n_features=40, save='reg_h1_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h2, n_features=40, save='reg_h2_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"UCB\", h3, n_features=40, save='reg_h3_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombLinTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h1, n_features=20, save='reg_h1_CombLinTS_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h2, n_features=20, save='reg_h2_CombLinTS_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h3, n_features=20, save='reg_h3_CombLinTS_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h1, n_features=40, save='reg_h1_CombLinTS_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h2, n_features=40, save='reg_h2_CombLinTS_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h3, n_features=40, save='reg_h3_CombLinTS_40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment B: Ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=20, hidden_size=20, save='reg_h1_CNUCB_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=20, save='reg_h1_CNTS_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=20, n_samples=50, save='reg_h1_CNTSOpt_20_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=20, hidden_size=20, save='reg_h2_CNUCB_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=20, save='reg_h2_CNTS_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=20, n_samples=50, save='reg_h2_CNTSOpt_20_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=20, hidden_size=20, save='reg_h3_CNUCB_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=20, save='reg_h3_CNTS_20_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=20, n_samples=50, save='reg_h3_CNTSOpt_20_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=20, hidden_size=40, save='reg_h1_CNUCB_20_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=40, save='reg_h1_CNTS_20_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=40, n_samples=50, save='reg_h1_CNTSOpt_20_40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=20, hidden_size=40, save='reg_h2_CNUCB_20_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=40, save='reg_h2_CNTS_20_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=40, n_samples=50, save='reg_h2_CNTSOpt_20_40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=20, hidden_size=40, save='reg_h3_CNUCB_20_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=40, save='reg_h3_CNTS_20_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=40, n_samples=50, save='reg_h3_CNTSOpt_20_40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 20, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=20, hidden_size=80, save='reg_h1_CNUCB_20_80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=80, save='reg_h1_CNTS_20_80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=80, n_samples=50, save='reg_h1_CNTSOpt_20_80')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 20, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=20, hidden_size=80, save='reg_h2_CNUCB_20_80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=80, save='reg_h2_CNTS_20_80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=80, n_samples=50, save='reg_h2_CNTSOpt_20_80')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 20, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=20, hidden_size=80, save='reg_h3_CNUCB_20_80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=80, save='reg_h3_CNTS_20_80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=80, n_samples=50, save='reg_h3_CNTSOpt_20_80')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=20, hidden_size=100, save='reg_h1_CNUCB_20_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=100, save='reg_h1_CNTS_20_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=20, hidden_size=100, n_samples=50, save='reg_h1_CNTSOpt_20_100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=20, hidden_size=100, save='reg_h2_CNUCB_20_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=100, save='reg_h2_CNTS_20_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=20, hidden_size=100, n_samples=50, save='reg_h2_CNTSOpt_20_100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=20, hidden_size=100, save='reg_h3_CNUCB_20_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=100, save='reg_h3_CNTS_20_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=20, hidden_size=100, n_samples=50, save='reg_h3_CNTSOpt_20_100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=40, hidden_size=60, save='reg_h1_CNUCB_40_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=40, hidden_size=60, save='reg_h1_CNTS_40_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=40, hidden_size=60, n_samples=50, save='reg_h1_CNTSOpt_40_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=40, hidden_size=60, save='reg_h2_CNUCB_40_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=40, hidden_size=60, save='reg_h2_CNTS_40_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=40, hidden_size=60, n_samples=50, save='reg_h2_CNTSOpt_40_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=40, hidden_size=60, save='reg_h3_CNUCB_40_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=40, hidden_size=60, save='reg_h3_CNTS_40_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=40, hidden_size=60, n_samples=50, save='reg_h3_CNTSOpt_40_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 80, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=80, hidden_size=60, save='reg_h1_CNUCB_80_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=80, hidden_size=60, save='reg_h1_CNTS_80_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=80, hidden_size=60, n_samples=50, save='reg_h1_CNTSOpt_80_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 80, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=80, hidden_size=60, save='reg_h2_CNUCB_80_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=80, hidden_size=60, save='reg_h2_CNTS_80_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=80, hidden_size=60, n_samples=50, save='reg_h2_CNTSOpt_80_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 80, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=80, hidden_size=60, save='reg_h3_CNUCB_80_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=80, hidden_size=60, save='reg_h3_CNTS_80_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=80, hidden_size=60, n_samples=50, save='reg_h3_CNTSOpt_80_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h1, 100, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h1, n_features=100, hidden_size=60, save='reg_h1_CNUCB_100_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=100, hidden_size=60, save='reg_h1_CNTS_100_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h1, n_features=100, hidden_size=60, n_samples=50, save='reg_h1_CNTSOpt_100_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h2, 100, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h2, n_features=100, hidden_size=60, save='reg_h2_CNUCB_100_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=100, hidden_size=60, save='reg_h2_CNTS_100_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h2, n_features=100, hidden_size=60, n_samples=50, save='reg_h2_CNTSOpt_100_60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h3, 100, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"UCB\", h3, n_features=100, hidden_size=60, save='reg_h3_CNUCB_100_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=100, hidden_size=60, save='reg_h3_CNTS_100_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(Neural, \"TS\", h3, n_features=100, hidden_size=60, n_samples=50, save='reg_h3_CNTSOpt_100_60')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
