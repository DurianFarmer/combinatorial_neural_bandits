{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4Q1y1fVZBNJ"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1612114370931,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "BxJjrGbzZBNM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "import abc\n",
    "\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from codes import *\n",
    "\n",
    "if not os.path.exists('regrets'):\n",
    "    os.mkdir('regrets')\n",
    "    \n",
    "\n",
    "## Hidden function\n",
    "SEED = 777\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izb_VuXOZBNT"
   },
   "source": [
    "# Experiment descirption\n",
    "### Hidden functions\n",
    "- Linear: $h_{1}(\\mathbf{x}_{t,i}) = \\mathbf{x}_{t,i}^{\\top}\\mathbf{a}$\n",
    "- Quadratic: $h_{2}(\\mathbf{x}_{t,i}) = (\\mathbf{x}_{t,i}^{\\top}\\mathbf{a})^{2}$\n",
    "- Non-linear: $h_{3}(\\mathbf{x}_{t,i}) = \\cos(\\pi \\mathbf{x}_{t,i}^{\\top}\\mathbf{a})$\n",
    "- where $\\mathbf{a} \\sim N(0,1)$ and then regularized\n",
    "\n",
    "### For each hidden function, compare the following algorithms\n",
    "- CombLinUCB\n",
    "- CombLinTS\n",
    "- CN-UCB\n",
    "- CN-TS(1): single reward sample\n",
    "- CN-TS(30): optimistic sampling, sample size = 30 (default sample size is 1)\n",
    "\n",
    "### Ablation study of feature dimension *d* and neural network width *m*\n",
    "- Default value: $d = 20, m = 20$\n",
    "- $d = \\{20, 40\\}$  for all algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giwELIVSZBNT"
   },
   "source": [
    "# Experiment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1612114697379,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "qBJKM4RXZBNa"
   },
   "outputs": [],
   "source": [
    "def inv_sherman_morrison_iter(a, A_inv):\n",
    "    \"\"\"Inverse of a matrix for combinatorial case.\n",
    "    \"\"\"\n",
    "    temp = A_inv.float()    \n",
    "    for u in a:\n",
    "        u = u.float()\n",
    "        Au = torch.matmul(temp, u)\n",
    "        temp = temp - torch.ger(Au, Au)/(1+torch.matmul(u.T, Au))    \n",
    "    return temp       \n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Template for fully connected neural network for scalar approximation.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_size=1, \n",
    "                 hidden_size=2,\n",
    "                 n_layers=1,\n",
    "                 activation='ReLU',\n",
    "                 p=0.0,\n",
    "                ):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        if self.n_layers == 1:\n",
    "            self.layers = [nn.Linear(input_size, 1)]                        \n",
    "        else:\n",
    "            size  = [input_size] + [hidden_size,] * (self.n_layers-1) + [1]\n",
    "            ##\n",
    "            self.layers = [nn.Linear(size[i], size[i+1], bias=False) \\\n",
    "                           for i in range(self.n_layers)]\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "        \n",
    "        # activation function\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == 'ReLU':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'LeakyReLU':\n",
    "            self.activation = nn.LeakyReLU(negative_slope=0.1)\n",
    "        else:\n",
    "            raise Exception('{} not an available activation'.format(activation))\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_layers-1):\n",
    "            x = self.dropout(self.activation(self.layers[i](x)))\n",
    "        x = self.layers[-1](x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit():\n",
    "    def __init__(self,\n",
    "                 T,\n",
    "                 n_arms,                 \n",
    "                 n_features,                                  \n",
    "                 h,                                                   \n",
    "                 noise_std=1.0,                 \n",
    "                 n_assortment=1,\n",
    "                 n_samples=1,\n",
    "                 round_reward_function=sum,\n",
    "                 device=torch.device('cpu')\n",
    "                ):\n",
    "        # number of rounds\n",
    "        self.T = T\n",
    "        # number of arms\n",
    "        self.n_arms = n_arms\n",
    "        # number of features for each arm\n",
    "        self.n_features = n_features        \n",
    "        \n",
    "        # average reward function\n",
    "        # h : R^d -> R\n",
    "        self.h = h\n",
    "\n",
    "        # standard deviation of Gaussian reward noise\n",
    "        self.noise_std = noise_std\n",
    "        \n",
    "        # number of assortment (top-K)\n",
    "        self.n_assortment = n_assortment                \n",
    "        \n",
    "        # (TS) number of samples for each round and arm\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "        # round reward function\n",
    "        self.round_reward_function = round_reward_function                \n",
    "        \n",
    "        # device\n",
    "        self.device = device\n",
    "        \n",
    "        # generate random features\n",
    "        self.reset()\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def arms(self):\n",
    "        \"\"\"Return [0, ...,n_arms-1]\n",
    "        \"\"\"\n",
    "        return range(self.n_arms)\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Generate new features and new rewards.\n",
    "        \"\"\"\n",
    "        self.reset_features()\n",
    "        self.reset_rewards()\n",
    "\n",
    "    def reset_features(self):\n",
    "        \"\"\"Generate normalized random N(0,1) features.\n",
    "        \"\"\"        \n",
    "        x = np.random.randn(self.T, self.n_arms, self.n_features)\n",
    "        x /= np.repeat(np.linalg.norm(x, axis=-1, ord=2), self.n_features).reshape(self.T, self.n_arms, self.n_features)\n",
    "        self.features = torch.from_numpy(x).to(self.device)\n",
    "\n",
    "    def reset_rewards(self):\n",
    "        \"\"\"Generate rewards for each arm and each round,\n",
    "        following the reward function h + Gaussian noise.\n",
    "        \"\"\"            \n",
    "        self.rewards = torch.Tensor(\n",
    "            [\n",
    "                self.h( self.features[t, k] ) + self.noise_std*torch.randn(1).to(self.device)\\\n",
    "                for t,k in itertools.product(range(self.T), range(self.n_arms))\n",
    "            ]\n",
    "        ).reshape(self.T, self.n_arms)\n",
    "\n",
    "        ## to be used only to compute regret, NOT by the algorithm itself        \n",
    "        a = self.rewards.to('cpu').numpy()\n",
    "        ind = np.argpartition(a, -1*self.n_assortment, axis=1)[:,-1*self.n_assortment:]        \n",
    "        s_ind = np.array([list(ind[i][np.argsort(a[i][ind[i]])][::-1]) for i in range(0, np.shape(a)[0])])\n",
    "        \n",
    "        self.best_super_arm = torch.from_numpy(s_ind).to(self.device)\n",
    "        self.best_rewards = torch.Tensor([a[i][s_ind[i]] for i in range(0,np.shape(a)[0])]).to(self.device)\n",
    "        self.best_round_reward = self.round_reward_function(self.best_rewards).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1612114698036,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "BDp-SK0YZBNb"
   },
   "outputs": [],
   "source": [
    "class UCB_TS(abc.ABC):\n",
    "    \"\"\"Base class for UCB and TS methods.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ucb_ts, ## A string. \"UCB\" for UCB, \"TS\" for TS\n",
    "                 bandit,\n",
    "                 reg_factor=1.0,\n",
    "                 confidence_scaling_factor=1, ## for UCB, gamma\n",
    "                 exploration_variance=1, ## for TS, nu\n",
    "                 delta=0.1,\n",
    "                 training_period=1,\n",
    "                 throttle=int(1e2),\n",
    "                 device=torch.device('cpu')\n",
    "                ):\n",
    "        ## select whether UCB or TS\n",
    "        self.ucb_ts = ucb_ts\n",
    "        # bandit object, contains features and generated rewards\n",
    "        self.bandit = bandit\n",
    "        # L2 regularization strength\n",
    "        self.reg_factor = reg_factor\n",
    "        # Confidence bound with probability 1-delta\n",
    "        self.delta = delta\n",
    "\n",
    "        # multiplier for the confidence bound            \n",
    "        self.confidence_scaling_factor = confidence_scaling_factor\n",
    "\n",
    "        # exploration variance for TS\n",
    "        self.exploration_variance = exploration_variance\n",
    "        \n",
    "        # train approximator only few rounds\n",
    "        self.training_period = training_period\n",
    "        \n",
    "        # throttle tqdm updates\n",
    "        self.throttle = throttle\n",
    "        \n",
    "        # device\n",
    "        self.device = device\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    ## for UCB\n",
    "    def reset_upper_confidence_bounds(self):\n",
    "        \"\"\"Initialize upper confidence bounds and related quantities.\n",
    "        \"\"\"\n",
    "        if self.ucb_ts == \"UCB\":\n",
    "            self.exploration_bonus = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.mu_hat = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.upper_confidence_bounds = torch.ones((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    ## for TS\n",
    "    def reset_sample_rewards(self):\n",
    "        \"\"\"Initialize sample rewards and related quantities.\n",
    "        \"\"\"\n",
    "        if self.ucb_ts == \"TS\":\n",
    "            self.sigma_square = torch.ones((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.mu_hat = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "            self.sample_rewards = torch.zeros((self.bandit.T, self.bandit.n_arms, self.bandit.n_samples)).to(self.device)\n",
    "            self.optimistic_sample_rewards = torch.zeros((self.bandit.T, self.bandit.n_arms)).to(self.device)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def reset_regrets(self):\n",
    "        \"\"\"Initialize regrets.\n",
    "        \"\"\"\n",
    "        self.regrets = torch.zeros(self.bandit.T).to(self.device)\n",
    "\n",
    "    def reset_actions(self):\n",
    "        \"\"\"Initialize cache of actions (actions: played set of arms of each round).\n",
    "        \"\"\"\n",
    "        self.actions = torch.zeros((self.bandit.T, self.bandit.n_assortment)).to(self.device)\n",
    "    \n",
    "    def reset_A_inv(self):\n",
    "        \"\"\"Initialize n_arms square matrices representing the inverses\n",
    "        of exploration bonus matrices.\n",
    "        \"\"\"\n",
    "        self.A_inv = (torch.eye(self.approximator_dim).to(self.device)/self.reg_factor).float()        \n",
    "    \n",
    "    def reset_grad_approx(self):\n",
    "        \"\"\"Initialize the gradient of the approximator w.r.t its parameters.\n",
    "        \"\"\"\n",
    "        self.grad_approx = torch.zeros((self.bandit.n_arms, self.approximator_dim)).to(self.device)\n",
    "        \n",
    "    def sample_action(self):        \n",
    "        \"\"\"Return the action (set of arms) to play based on current estimates\n",
    "        \"\"\"\n",
    "        ## for UCB\n",
    "        if self.ucb_ts == \"UCB\":\n",
    "            a = self.upper_confidence_bounds[self.iteration].to('cpu').numpy()\n",
    "        ## for TS\n",
    "        if self.ucb_ts == \"TS\":\n",
    "            a = self.optimistic_sample_rewards[self.iteration].to('cpu').numpy()\n",
    "\n",
    "        ind = np.argpartition(a, -1*self.bandit.n_assortment)[-1*self.bandit.n_assortment:]\n",
    "        s_ind = ind[np.argsort(a[ind])][::-1]\n",
    "        return torch.Tensor(s_ind.copy()).to(self.device)               \n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def reset(self):\n",
    "        \"\"\"Initialize variables of interest.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def approximator_dim(self):\n",
    "        \"\"\"Number of parameters used in the approximator.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def confidence_multiplier(self):\n",
    "        \"\"\"Multiplier for the confidence exploration bonus.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def update_confidence_bounds(self):\n",
    "        \"\"\"Update the confidence bounds for all arms at time t.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update_output_gradient(self):\n",
    "        \"\"\"Compute output gradient of the approximator w.r.t its parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def train(self):\n",
    "        \"\"\"Update approximator.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def predict(self):\n",
    "        \"\"\"Predict rewards based on an approximator.\n",
    "        To be defined in children classes.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    ## for UCB\n",
    "    def update_confidence_bounds(self):\n",
    "        \"\"\"Update confidence bounds and related quantities for all set of arms.\n",
    "        \"\"\"\n",
    "        # update self.grad_approx\n",
    "        self.update_output_gradient()\n",
    "        \n",
    "        # UCB exploration bonus\n",
    "        self.exploration_bonus[self.iteration] = torch.Tensor(\n",
    "            [\n",
    "                self.confidence_multiplier * torch.sqrt(torch.dot(self.grad_approx[a].float(), torch.matmul(self.A_inv.float(), self.grad_approx[a].T.float()))) for a in self.bandit.arms\n",
    "            ]\n",
    "        )        \n",
    "        \n",
    "        # update reward prediction mu_hat\n",
    "        self.predict()\n",
    "        \n",
    "        # estimated combined bound for reward\n",
    "        self.upper_confidence_bounds[self.iteration] = self.mu_hat[self.iteration] + self.exploration_bonus[self.iteration]\n",
    "\n",
    "    ## for TS\n",
    "    def update_sample_rewards(self):\n",
    "        \"\"\"Update sample rewards and related quantities for all set of arms.\n",
    "        \"\"\"        \n",
    "        # update self.grad_approx\n",
    "        self.update_output_gradient() \n",
    "        \n",
    "        # update sigma_square        \n",
    "        self.sigma_square[self.iteration] = torch.Tensor([self.reg_factor * \\\n",
    "                                             torch.dot(self.grad_approx[a], torch.matmul(self.A_inv, self.grad_approx[a].T)) \\\n",
    "                                             for a in self.bandit.arms]).to(self.device)\n",
    "                \n",
    "        # update reward prediction mu_hat\n",
    "        self.predict()\n",
    "        \n",
    "        # update sample reward\n",
    "        self.sample_rewards.to('cpu')\n",
    "        for a in self.bandit.arms:\n",
    "            for j in range(self.bandit.n_samples):\n",
    "                self.sample_rewards[self.iteration][a][j] = np.random.normal(loc = self.mu_hat[self.iteration, a].to('cpu'),\n",
    "                                                                             scale = (self.exploration_variance**2) * self.sigma_square[self.iteration, a].to('cpu')\n",
    "                                                                            )                                                                                                                                           \n",
    "        self.sample_rewards.to(self.device)\n",
    "        \n",
    "        # update optimistic sample reward for each arm\n",
    "        for a in self.bandit.arms:\n",
    "            self.optimistic_sample_rewards[self.iteration][a] = torch.max(self.sample_rewards[self.iteration][a])\n",
    "        \n",
    "    def update_A_inv(self):\n",
    "        \"\"\"Update A_inv by using an iteration of Sherman_Morrison formula\n",
    "        \"\"\"\n",
    "        self.A_inv = inv_sherman_morrison_iter(\n",
    "            self.grad_approx[self.action.to('cpu').numpy()],\n",
    "            self.A_inv\n",
    "        )               \n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"Run an episode of bandit.\n",
    "        \"\"\"\n",
    "        postfix = {\n",
    "            'total regret': 0.0,\n",
    "            '% optimal set of arms': 0.0,\n",
    "        }\n",
    "        with tqdm(total=self.bandit.T, postfix=postfix) as pbar:\n",
    "            for t in range(self.bandit.T):                \n",
    "                ## for UCB\n",
    "                if self.ucb_ts == \"UCB\":\n",
    "                    # update confidence of all set of arms based on observed features at time t\n",
    "                    self.update_confidence_bounds()\n",
    "                ## for TS\n",
    "                if self.ucb_ts == \"TS\":\n",
    "                    ## update sample rewards of all set of arms based on observed features at time t\n",
    "                    self.update_sample_rewards()                \n",
    "                \n",
    "                # pick action (set of arm) with the highest boosted estimated reward\n",
    "                self.action = self.sample_action()\n",
    "                self.actions[t] = self.action\n",
    "                # update approximator                          \n",
    "                self.train() ### lin and neural training are different\n",
    "                # update exploration indicator A_inv\n",
    "                self.update_A_inv()\n",
    "                \n",
    "                ## compute regret                \n",
    "                self.regrets[t] = self.bandit.best_round_reward[t] - self.bandit.round_reward_function(self.bandit.rewards[t, self.action.to('cpu').numpy()])                 \n",
    "                \n",
    "                # increment counter\n",
    "                self.iteration += 1\n",
    "                \n",
    "                # log\n",
    "                postfix['total regret'] += self.regrets[t].to('cpu').numpy()\n",
    "                n_optimal_arm = np.sum(\n",
    "                    np.prod(\n",
    "                        (self.actions[:self.iteration].to('cpu').numpy()==self.bandit.best_super_arm[:self.iteration].to('cpu').numpy())*1, \n",
    "                        axis=1)                                                          \n",
    "                )\n",
    "                postfix['% optimal set of arms'] = '{:.2%}'.format(n_optimal_arm / self.iteration)\n",
    "                \n",
    "                if t % self.throttle == 0:\n",
    "                    pbar.set_postfix(postfix)\n",
    "                    pbar.update(self.throttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1612114698036,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "4tvBEQ33ZBNg"
   },
   "outputs": [],
   "source": [
    "class Neural(UCB_TS):\n",
    "    \"\"\"CN-UCB or CN-TS.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ucb_ts, ## A string. \"UCB\" for UCB, \"TS\" for TS\n",
    "                 bandit,\n",
    "                 hidden_size=20,\n",
    "                 n_layers=2,\n",
    "                 reg_factor=1.0,\n",
    "                 delta=0.01,\n",
    "                 confidence_scaling_factor=1, ## for UCB\n",
    "                 exploration_variance=1, ## for TS\n",
    "                 training_window=100,\n",
    "                 p=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 epochs=1,\n",
    "                 training_period=1,\n",
    "                 throttle=1,\n",
    "                 device=torch.device('cpu'),\n",
    "                ):\n",
    "\n",
    "        # hidden size of the NN layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # number of layers\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # number of rewards in the training buffer\n",
    "        self.training_window = training_window\n",
    "        \n",
    "        # NN parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.device = device\n",
    "            \n",
    "        # dropout rate\n",
    "        self.p = p\n",
    "\n",
    "        # neural network\n",
    "        self.model = Model(input_size=bandit.n_features, \n",
    "                           hidden_size=self.hidden_size,\n",
    "                           n_layers=self.n_layers,\n",
    "                           p=self.p\n",
    "                          ).to(self.device)        \n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        super().__init__(ucb_ts,\n",
    "                         bandit, \n",
    "                         reg_factor=reg_factor,\n",
    "                         confidence_scaling_factor=confidence_scaling_factor, ## for UCB\n",
    "                         exploration_variance=exploration_variance, ## for TS\n",
    "                         delta=delta,\n",
    "                         throttle=throttle,\n",
    "                         training_period=training_period,\n",
    "                         device=self.device\n",
    "                        )\n",
    "\n",
    "    @property\n",
    "    def approximator_dim(self):\n",
    "        \"\"\"Sum of the dimensions of all trainable layers in the network.\n",
    "        \"\"\"\n",
    "        return sum(w.numel() for w in self.model.parameters() if w.requires_grad)\n",
    "    \n",
    "    @property\n",
    "    def confidence_multiplier(self):\n",
    "        \"\"\"Constant equal to confidence_scaling_factor\n",
    "        \"\"\"\n",
    "        return self.confidence_scaling_factor\n",
    "    \n",
    "    def update_output_gradient(self):\n",
    "        \"\"\"Get gradient of network prediction w.r.t network weights.\n",
    "        \"\"\"\n",
    "        for a in self.bandit.arms:\n",
    "            \n",
    "            x = self.bandit.features[self.iteration, a].reshape(1,-1).float()                \n",
    "            \n",
    "            self.model.zero_grad()\n",
    "            y = self.model(x)\n",
    "            y.backward()\n",
    "                        \n",
    "            self.grad_approx[a] = torch.cat([\n",
    "                w.grad.detach().flatten() / np.sqrt(self.hidden_size)\n",
    "                for w in self.model.parameters() if w.requires_grad]\n",
    "            ).to(self.device)\n",
    "            \n",
    "            \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal estimates.\n",
    "        \"\"\"\n",
    "        self.reset_upper_confidence_bounds() ## for UCB\n",
    "        self.reset_sample_rewards() ## for TS\n",
    "        self.reset_regrets()\n",
    "        self.reset_actions()\n",
    "        self.reset_A_inv()\n",
    "        self.reset_grad_approx()\n",
    "        self.iteration = 0\n",
    "\n",
    "    ## inital parameters\n",
    "    def set_init_param(self, parameters):\n",
    "        self.init_param = self.param_to_tensor(parameters)\n",
    "\n",
    "    ## torch Parameter object to Tensor object\n",
    "    def param_to_tensor(self, parameters):\n",
    "        a = torch.empty(1).to(self.device)\n",
    "        for p in parameters:\n",
    "            a = torch.cat(a,( p.data.flatten()))\n",
    "        return a[1:].to(self.device)    \n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Train neural approximator.        \n",
    "        \"\"\"\n",
    "        ### train only when training_period occurs\n",
    "        if self.iteration % self.training_period == 0:                        \n",
    "            iterations_so_far = range(np.max([0, self.iteration-self.training_window]), self.iteration+1)\n",
    "            actions_so_far = self.actions[np.max([0, self.iteration-self.training_window]):self.iteration+1].to('cpu').numpy() # this is a matrix            \n",
    "\n",
    "            temp = torch.cat([self.bandit.features[t, actions_so_far[i]] for i, t in enumerate(iterations_so_far)])\n",
    "            x_train = torch.reshape(temp, (1,-1,self.bandit.n_features)).squeeze().float().to(self.device)\n",
    "\n",
    "            temp = torch.cat([self.bandit.rewards[t, actions_so_far[i]] for i, t in enumerate(iterations_so_far)])\n",
    "            y_train = torch.reshape(temp, (1,-1)).squeeze().float().to(self.device)\n",
    "\n",
    "            # train mode\n",
    "            self.model.train()\n",
    "            for _ in range(self.epochs):\n",
    "                ## computing the regularization parameter\n",
    "                tmp = (self.param_to_tensor(self.model.parameters()) - self.init_param).to(torch.device('cpu')).numpy()\n",
    "                param_diff = np.linalg.norm(tmp)\n",
    "                regularization = (self.reg_factor*self.hidden_size*param_diff**2)/2\n",
    "\n",
    "                ## update weight\n",
    "                y_pred = self.model.forward(x_train).squeeze()\n",
    "                ### loss = nn.MSELoss()(y_train, y_pred)\n",
    "                loss = nn.MSELoss(reduction='sum')(y_train, y_pred)/2 + regularization            \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        else:\n",
    "            pass\n",
    "                                        \n",
    "    def predict(self):\n",
    "        \"\"\"Predict reward.\n",
    "        \"\"\"\n",
    "        # eval mode\n",
    "        self.model.eval()        \n",
    "        self.mu_hat[self.iteration] = self.model.forward(self.bandit.features[self.iteration].float()).detach().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(UCB_TS):\n",
    "    \"\"\"LinUCB or LinTS.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ucb_ts, ## A string. \"UCB\" for UCB, \"TS\" for TS\n",
    "                 bandit,\n",
    "                 reg_factor=1.0,\n",
    "                 delta=0.01,\n",
    "                 bound_theta=1.0,\n",
    "                 confidence_scaling_factor=1, ## for UCB                 \n",
    "                 exploration_variance=1, ## for TS\n",
    "                 throttle=int(1e2),\n",
    "                 device=torch.device('cpu')\n",
    "                ):\n",
    "\n",
    "        # range of the linear predictors\n",
    "        self.bound_theta = bound_theta\n",
    "        \n",
    "        super().__init__(ucb_ts, \n",
    "                         bandit, \n",
    "                         reg_factor=reg_factor,\n",
    "                         confidence_scaling_factor=confidence_scaling_factor, ## for UCB\n",
    "                         exploration_variance=exploration_variance, ## for TS\n",
    "                         delta=delta,\n",
    "                         throttle=throttle,\n",
    "                        )\n",
    "        self.device = device\n",
    "\n",
    "    @property\n",
    "    def approximator_dim(self):\n",
    "        \"\"\"Number of parameters used in the approximator.\n",
    "        \"\"\"\n",
    "        return self.bandit.n_features\n",
    "    \n",
    "    def update_output_gradient(self):\n",
    "        \"\"\"For linear approximators, simply returns the features.\n",
    "        \"\"\"\n",
    "        self.grad_approx = self.bandit.features[self.iteration]\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Return the internal estimates\n",
    "        \"\"\"\n",
    "        self.reset_upper_confidence_bounds() ## for UCB\n",
    "        self.reset_sample_rewards() ## for TS\n",
    "        self.reset_regrets()\n",
    "        self.reset_actions()\n",
    "        self.reset_A_inv()\n",
    "        self.reset_grad_approx()\n",
    "        self.iteration = 0\n",
    "\n",
    "        # randomly initialize linear predictors within their bounds        \n",
    "        self.theta = torch.from_numpy(np.random.uniform(-1, 1, self.bandit.n_features) * self.bound_theta).to(self.device)\n",
    "\n",
    "        # initialize reward-weighted features sum at zero\n",
    "        self.b = torch.zeros(self.bandit.n_features).to(self.device).float()\n",
    "\n",
    "    @property\n",
    "    def confidence_multiplier(self):\n",
    "        \"\"\"Use exploration variance (nu) instead of confidence scaling factor (gamma)\n",
    "        \"\"\"\n",
    "        return self.confidence_scaling_factor\n",
    "    \n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Update linear predictor theta.\n",
    "        \"\"\"        \n",
    "        self.theta = torch.matmul(self.A_inv.float(), self.b.float())                      \n",
    "        tmp = torch.from_numpy(np.sum(np.array([ self.bandit.rewards[self.iteration][i].to('cpu').numpy()*\n",
    "                      self.bandit.features[self.iteration, self.actions[self.iteration].to('cpu').numpy()][i].to('cpu').numpy()\n",
    "                                   for i in range(0, self.bandit.n_assortment) ]\n",
    "                             ), axis = 0)).to(self.device)\n",
    "        self.b = self.b.double() + tmp.double()\n",
    "            \n",
    "    def predict(self):\n",
    "        \"\"\"Predict reward.\n",
    "        \"\"\"\n",
    "        self.mu_hat[self.iteration] = torch.Tensor(\n",
    "            [\n",
    "                torch.dot(self.bandit.features[self.iteration, a], self.theta.double()) for a in self.bandit.arms\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajS2SB-QZBNU"
   },
   "source": [
    "### Hidden function, bandit, learning algorithm and regret settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1612114696060,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "q4upzAevZBNU"
   },
   "outputs": [],
   "source": [
    "h1 = \"h1\"\n",
    "h2 = \"h2\"\n",
    "h3 = \"h3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(lin_neural, ucb_ts, h_str, n_features=20, hidden_size=100, n_samples=1, save = ''):\n",
    "    \"\"\" kind explanation\n",
    "    \"\"\"\n",
    "    ## Hidden function\n",
    "    # tmp = np.random.uniform(low=-1.0, high=1.0, size=n_features)\n",
    "    tmp = np.random.randn(n_features)\n",
    "    a = torch.from_numpy(tmp / np.linalg.norm(tmp, ord=2)).to(device)\n",
    "\n",
    "    if h_str == \"h1\":\n",
    "        def h(x):\n",
    "            return torch.dot(x, a).to(device)    \n",
    "    elif h_str == \"h2\":\n",
    "        def h(x):\n",
    "            return (torch.dot(x, a)**2).to(device)    \n",
    "    elif h_str == \"h3\":\n",
    "        def h(x):\n",
    "            PI = 3.14\n",
    "            return torch.cos(PI*torch.dot(x, a)).to(device)\n",
    "    \n",
    "    ## Bandit\n",
    "    bandit = Bandit(T,\n",
    "                  n_arms,\n",
    "                  n_features, \n",
    "                  h,\n",
    "                  noise_std=noise_std,\n",
    "                  n_assortment=n_assortment,\n",
    "                  n_samples=n_samples,\n",
    "                  round_reward_function=F,\n",
    "                  device=device\n",
    "                 )\n",
    "    \n",
    "    ## Learning algorithm and regret\n",
    "    regrets = np.empty((n_sim, T))\n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        bandit.reset_rewards()\n",
    "        \n",
    "        if lin_neural == Neural:\n",
    "            model = Neural(ucb_ts,\n",
    "                           bandit,\n",
    "                           hidden_size,\n",
    "                           reg_factor=reg_factor,\n",
    "                           delta=delta,\n",
    "                           confidence_scaling_factor=confidence_scaling_factor,\n",
    "                           exploration_variance=exploration_variance,\n",
    "                           p=p,\n",
    "                           training_window=training_window,\n",
    "                           learning_rate=learning_rate,\n",
    "                           epochs=epochs,\n",
    "                           training_period=training_period,\n",
    "                           device=device\n",
    "                          )\n",
    "            \n",
    "            model.set_init_param(model.model.parameters()) # keep initial parameters for regularization\n",
    "        \n",
    "        ##TODO\n",
    "        if lin_neural == Lin:\n",
    "            model = lin_neural(ucb_ts,\n",
    "                               bandit,\n",
    "                                reg_factor=reg_factor,\n",
    "                               delta=delta,\n",
    "                               confidence_scaling_factor=confidence_scaling_factor,\n",
    "                               exploration_variance=exploration_variance\n",
    "                              )\n",
    "        \n",
    "        \n",
    "        model.run()\n",
    "        regrets[i] = np.cumsum(model.regrets.to('cpu').numpy())\n",
    "        np.cumsum(model.regrets.to('cpu').numpy())\n",
    "    if save: # save regrets\n",
    "        np.save('regrets/' + save, regrets)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDeUY26iZBNk"
   },
   "source": [
    "# Experiment A: (h, d, m) - Algorithm - Regret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxAGtJeFZBNO"
   },
   "source": [
    "### Bandit settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1612114630240,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "x2DzcHGzZBNO"
   },
   "outputs": [],
   "source": [
    "T = 1000\n",
    "n_sim = 10 # number of simulations\n",
    "\n",
    "\n",
    "n_arms = 20 # N\n",
    "n_features_default = 20 # d\n",
    "n_assortment = 4 # K\n",
    "n_samples = 30 # M, number of samples per each round and arm, for TS\n",
    "\n",
    "noise_std = 0.01 # noise of reward: xi = noise_std*N(0,1)\n",
    "\n",
    "\n",
    "def F(x): # round_reward_function\n",
    "    if x.dim == 1: # if x is a vector\n",
    "        return torch.sum(x)\n",
    "    else: # if x is a matrix\n",
    "        return torch.sum(x, dim=-1)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sugHGUJWZBNP"
   },
   "source": [
    "### Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "executionInfo": {
     "elapsed": 756,
     "status": "ok",
     "timestamp": 1612114633530,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "c9bthPvvZBNQ"
   },
   "outputs": [],
   "source": [
    "reg_factor = 0.5 # lambda\n",
    "delta = 0.1 # delta\n",
    "exploration_variance = 1 # nu, for TS and CombLinUCB\n",
    "confidence_scaling_factor = 1 # gamma, for CN-UCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0-F-FUjZBNQ"
   },
   "source": [
    "### Neural network settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1612114633902,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "2v72Wp28ZBNR"
   },
   "outputs": [],
   "source": [
    "hidden_size_default = 20 # m\n",
    "epochs = 100 # repeat training for each period\n",
    "training_period = 5 ### training period\n",
    "training_window = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "p = 0.0 # no dropout\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "executionInfo": {
     "elapsed": 617,
     "status": "ok",
     "timestamp": 1612114693709,
     "user": {
      "displayName": "Kyuwook Chai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhabeIY0xp9P_Ac7iq3fvZfABsXRjK_t3iH11-z=s64",
      "userId": "03320902743106715829"
     },
     "user_tz": -540
    },
    "id": "9DEQ17WIZBNS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kiLkgOmZBNp"
   },
   "source": [
    "### CombLinUCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "tV68lc_TZBNp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 450.02it/s, total regret=3.37e+3, % optimal set of arms=2.16%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 449.75it/s, total regret=3.29e+3, % optimal set of arms=1.25%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 448.53it/s, total regret=3.2e+3, % optimal set of arms=0.57%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 445.83it/s, total regret=2.77e+3, % optimal set of arms=1.82%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 440.01it/s, total regret=3.17e+3, % optimal set of arms=1.58%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 431.56it/s, total regret=3.5e+3, % optimal set of arms=0.52%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 444.50it/s, total regret=2.73e+3, % optimal set of arms=2.61%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 445.93it/s, total regret=2.96e+3, % optimal set of arms=1.50%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 450.82it/s, total regret=2.89e+3, % optimal set of arms=1.82%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 440.26it/s, total regret=3.11e+3, % optimal set of arms=0.91%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Lin, \"UCB\", h1, n_features=20, save='reg_h1_CombLinUCB_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "i_dSDoeYZBNp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 448.31it/s, total regret=3.68e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:21<00:00, 457.49it/s, total regret=4.03e+3, % optimal set of arms=0.01%]\n",
      "100%|██████████| 10000/10000 [00:21<00:00, 456.70it/s, total regret=3.18e+3, % optimal set of arms=0.03%]\n",
      "100%|██████████| 10000/10000 [00:21<00:00, 457.68it/s, total regret=4.06e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:21<00:00, 458.00it/s, total regret=3.83e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:21<00:00, 459.00it/s, total regret=3.75e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 453.51it/s, total regret=3.47e+3, % optimal set of arms=0.01%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 449.63it/s, total regret=3.51e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 448.59it/s, total regret=4.12e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:21<00:00, 455.46it/s, total regret=3.89e+3, % optimal set of arms=0.00%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Lin, \"UCB\", h2, n_features=20, save='reg_h2_CombLinUCB_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "GCns0kyIZBNp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 443.74it/s, total regret=8e+3, % optimal set of arms=0.01%]  \n",
      "100%|██████████| 10000/10000 [00:22<00:00, 450.33it/s, total regret=8.02e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 451.14it/s, total regret=8.11e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 448.05it/s, total regret=8.01e+3, % optimal set of arms=0.01%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 449.51it/s, total regret=8.05e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 448.09it/s, total regret=7.97e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 449.74it/s, total regret=8.06e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 451.98it/s, total regret=8.12e+3, % optimal set of arms=0.01%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 445.34it/s, total regret=7.93e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 447.87it/s, total regret=8.14e+3, % optimal set of arms=0.00%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Lin, \"UCB\", h3, n_features=20, save='reg_h3_CombLinUCB_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "Rz7fSzkhZBNq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 449.70it/s, total regret=2.25e+3, % optimal set of arms=0.59%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 443.75it/s, total regret=3.26e+3, % optimal set of arms=0.22%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 444.58it/s, total regret=2.65e+3, % optimal set of arms=0.45%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 447.03it/s, total regret=2.79e+3, % optimal set of arms=0.42%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 446.45it/s, total regret=2.59e+3, % optimal set of arms=0.69%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 447.80it/s, total regret=2.66e+3, % optimal set of arms=0.47%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 446.38it/s, total regret=3.76e+3, % optimal set of arms=0.15%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 449.17it/s, total regret=2.81e+3, % optimal set of arms=0.33%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 450.85it/s, total regret=3.33e+3, % optimal set of arms=0.32%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 441.12it/s, total regret=2.79e+3, % optimal set of arms=0.60%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Lin, \"UCB\", h1, n_features=40, save='reg_h1_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "fBZ4x0eZZBNq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 450.66it/s, total regret=2.1e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 445.79it/s, total regret=2.09e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 447.72it/s, total regret=2.12e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 446.73it/s, total regret=2.13e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 450.36it/s, total regret=2.06e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 447.18it/s, total regret=2.14e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 444.08it/s, total regret=2.12e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 450.53it/s, total regret=1.97e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 450.84it/s, total regret=2.13e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 452.56it/s, total regret=2.12e+3, % optimal set of arms=0.00%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Lin, \"UCB\", h2, n_features=40, save='reg_h2_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "mP-xZj9WZBNq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 446.50it/s, total regret=4.56e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 451.68it/s, total regret=4.46e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 449.73it/s, total regret=4.52e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 450.85it/s, total regret=4.42e+3, % optimal set of arms=0.01%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 445.37it/s, total regret=4.4e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 448.41it/s, total regret=4.62e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 448.84it/s, total regret=4.59e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 451.37it/s, total regret=4.47e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 445.71it/s, total regret=4.43e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 449.05it/s, total regret=4.43e+3, % optimal set of arms=0.00%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Lin, \"UCB\", h3, n_features=40, save='reg_h3_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "Rz7fSzkhZBNq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 435.87it/s, total regret=2.82e+3, % optimal set of arms=0.13%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 437.18it/s, total regret=2.88e+3, % optimal set of arms=0.12%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 437.68it/s, total regret=2.4e+3, % optimal set of arms=0.27%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 436.31it/s, total regret=2.6e+3, % optimal set of arms=0.18%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 435.42it/s, total regret=2.77e+3, % optimal set of arms=0.10%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 436.64it/s, total regret=2.33e+3, % optimal set of arms=0.36%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 426.82it/s, total regret=2.47e+3, % optimal set of arms=0.17%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 433.12it/s, total regret=2.61e+3, % optimal set of arms=0.21%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 437.87it/s, total regret=2.94e+3, % optimal set of arms=0.10%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 435.03it/s, total regret=3.08e+3, % optimal set of arms=0.16%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Lin, \"UCB\", h1, n_features=80, save='reg_h1_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "fBZ4x0eZZBNq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 432.83it/s, total regret=1.15e+3, % optimal set of arms=0.01%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 438.27it/s, total regret=1.14e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 433.23it/s, total regret=1.02e+3, % optimal set of arms=0.01%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 432.08it/s, total regret=1.16e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 436.20it/s, total regret=1.15e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 429.13it/s, total regret=1.04e+3, % optimal set of arms=0.01%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 436.68it/s, total regret=1.11e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 435.07it/s, total regret=1.16e+3, % optimal set of arms=0.01%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 433.39it/s, total regret=1.14e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 437.16it/s, total regret=1.12e+3, % optimal set of arms=0.01%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Lin, \"UCB\", h2, n_features=80, save='reg_h2_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "mP-xZj9WZBNq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 429.38it/s, total regret=2.48e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 437.39it/s, total regret=2.46e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 430.32it/s, total regret=2.44e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 437.34it/s, total regret=2.45e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 434.72it/s, total regret=2.61e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 431.51it/s, total regret=2.47e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 434.87it/s, total regret=2.43e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 437.18it/s, total regret=2.43e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 435.78it/s, total regret=2.44e+3, % optimal set of arms=0.00%]\n",
      "100%|██████████| 10000/10000 [00:23<00:00, 429.08it/s, total regret=2.43e+3, % optimal set of arms=0.00%]\n"
     ]
    }
   ],
   "source": [
    "experiment(Lin, \"UCB\", h3, n_features=80, save='reg_h3_CombLinUCB_40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWGIqRfhZBNq"
   },
   "source": [
    "### CombLinTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3QC7OdrZBNq"
   },
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h1, n_features=20, save='reg_h1_CombLinTS_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJmMu9GMZBNq"
   },
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h2, n_features=20, save='reg_h2_CombLinTS_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziNo76O1ZBNr"
   },
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h3, n_features=20, save='reg_h3_CombLinTS_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGXvF_wPZBNr"
   },
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h1, n_features=40, save='reg_h1_CombLinTS_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_d-zaHuZBNr"
   },
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h2, n_features=40, save='reg_h2_CombLinTS_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOYSPOMWZBNr"
   },
   "outputs": [],
   "source": [
    "experiment(Lin, \"TS\", h3, n_features=40, save='reg_h3_CombLinTS_40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSOgm7whZBNr"
   },
   "source": [
    "---------------------------------------"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4H9aXScLZBNk",
    "L_N_m7AFZBNl",
    "hJY9XrDLZBNm",
    "epEs02A1ZBNn",
    "d0sbFSlFZBNo",
    "NPOILfGyZBNo",
    "2kiLkgOmZBNp",
    "mWGIqRfhZBNq",
    "SltoRMfyZBNr",
    "1gmXsux9ZBNs",
    "tjXEJNxQZBNt",
    "zp9KsTdbZBNt",
    "QyQGIg1WZBNu",
    "adMLERWmZBNu",
    "fAOeYOEWZBNv",
    "ksgskGR_ZBNw",
    "3fdRizR9ZBNw",
    "pj9ZZ57TZBNx",
    "tzYUU36fZBNx",
    "A7mqTpA5ZBNy",
    "2nkj062kZBNz",
    "9lIDEjnVZBN0",
    "UD4tMhgyZBN1",
    "1vA-6tsGZBN2",
    "CR2mquYvZBN2",
    "oBjB2zifZBN3",
    "C2jEGbBLZBN3",
    "h86J_GTMZBN4",
    "aiKyZJj3ZBN5",
    "6M2w1wXTZBN5",
    "9KA0DHCzZBN6",
    "ct4UkKj2ZBN6",
    "KmFOyn3bZBN7",
    "GidF2tcVZBN7",
    "AY2N28SVZBN8",
    "_wC-xaoFZBN9",
    "qv82nCIRZBN9",
    "WXkandK1ZBN-",
    "TVKsvkbNZBN-",
    "mSHybzJ3ZBN_",
    "eQa6-hhRZBOA",
    "67icjm2_ZBOB",
    "B1IrNW0XZBOB"
   ],
   "name": "Copy of Experiments-ver3.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/DurianFarmer/combinatorial_neural_bandits/blob/master/Experiments-ver3.ipynb",
     "timestamp": 1612112504266
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
